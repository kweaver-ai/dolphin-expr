#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Experiment analysis main entry script

This is the recommended unified entry point that provides all experiment analysis features.

Usage:
    # General analysis (default)
    ./bin/analyst bird_baseline_20250804_105810
    ./bin/analyst bird_baseline_20250804_105810 --general
    
    # Agent execution analysis
    ./bin/analyst bird_baseline_20250804_105810 --analysis --run run_001 --case 001

Architecture:
    - analyze.py: unified entry point and CLI parsing
    - experiment_coordinator.py: coordinator logic and module management
    - general_reporter.py: overall report generation
    - execution_analyzer.py: agent execution analysis
    - experiment_analyzer.py: data loader (reuses existing logic)
"""

import sys
import os
from pathlib import Path
# Add repo root to path for imports (project_env, etc.)
repo_root = Path(__file__).resolve().parent.parent
if str(repo_root) not in sys.path:
    sys.path.insert(0, str(repo_root))
# Add analyst directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "analyst"))
from experiment_coordinator import ExperimentCoordinator
from simulation_inject import SimulationInjector


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Experiment analysis helper entry script")
    parser.add_argument("experiment_path", help="Experiment directory path (under env/)")
    
    # Analysis mode options
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument("--general", action="store_true",
                           help="Run general analysis mode (generate comprehensive reports)")
    mode_group.add_argument("--analysis", action="store_true",
                           help="Run agent execution analysis mode")
    mode_group.add_argument("--cross-run-analysis", action="store_true",
                           help="Run cross-run analysis mode and filter cases by accuracy threshold")
    mode_group.add_argument("--sim-inject", action="store_true",
                           help="Run simulation-inject mode to improve hard cases with optimized injects")

    # Agent execution analysis arguments
    parser.add_argument("--run", help="Run name (for --analysis mode)")
    parser.add_argument("--case", help="Case number (usable in --analysis or --cross-run-analysis; supports case_001, 001, or 1)")
    parser.add_argument("--summary", action="store_true", help="Run summary mode (for --analysis --run)")
    parser.add_argument("--failed-only", action="store_true", help="Analyze failed cases only (for --analysis --run)")
    parser.add_argument("--knows", help="Path to a knowledge file or directory (for --analysis mode)")

    # Cross-run analysis arguments
    parser.add_argument("--max-accuracy", type=float,
                       help="Max accuracy threshold (percent, e.g., 30 means 30%%); analyze cases below this threshold")
    parser.add_argument("--report-csv", help="Path to a general report CSV file (used to read accuracy data)")

    # Simulation-inject arguments
    parser.add_argument("--case_id", help="Case ID for simulation-inject (optional; if omitted, process all low-accuracy cases)")
    parser.add_argument("--entrypoint", help="Override entrypoint for execution")
    parser.add_argument("--inject-var", default="injects", help="Inject variable name (default: injects)")
    parser.add_argument("--sim-timeout", type=int, default=500,
                        help="Simulation-inject subprocess timeout (seconds). 0 means no limit. Default: 500")
    parser.add_argument("--max-iterations", type=int, default=5,
                        help="Max simulation iterations per case (default: 5)")
    parser.add_argument("--accuracy-threshold", type=float, default=10.0,
                        help="Accuracy threshold for batch mode (percent); process only cases below this threshold (default: 10%%)")
    parser.add_argument("--top-n", type=int, default=5,
                        help="When aggregating injects, pick the top-N most voted candidate injects (default: 5)")

    args = parser.parse_args()
    
    experiment_input = args.experiment_path

    # Build full path
    if os.path.isabs(experiment_input):
        experiment_path = Path(experiment_input)
    else:
        # Relative path, based on env/ directory
        script_dir = Path(__file__).parent.parent
        experiment_path = script_dir / "env" / experiment_input

    if not experiment_path.exists():
        print(f"ÈîôËØØ: ÂÆûÈ™åË∑ØÂæÑ‰∏çÂ≠òÂú®: {experiment_path}")

        # List available experiments
        env_dir = Path(__file__).parent.parent / "env"
        if env_dir.exists():
            experiments = [d.name for d in env_dir.iterdir() if d.is_dir()]
            if experiments:
                print(f"\nÂèØÁî®ÁöÑÂÆûÈ™å:")
                for exp in sorted(experiments):
                    print(f"  {exp}")
        return 1

    print(f"ÂºÄÂßãÂàÜÊûêÂÆûÈ™å: {experiment_path.name}")
    print(f"ÂÆûÈ™åË∑ØÂæÑ: {experiment_path}")
    print("-" * 60)

    # Create coordinator
    coordinator = ExperimentCoordinator(experiment_path)

    # Dispatch based on selected mode
    if args.sim_inject:
        # Simulation-inject mode (smart optimization) -> implemented by SimulationInjector
        injector = SimulationInjector(
            experiment_path=experiment_path,
            data_loader=coordinator.data_loader,
            cross_run_analysis_callback=coordinator.run_cross_run_analysis,
        )
        if args.case_id:
            # Single-case processing
            print("üöÄ ÂêØÂä®Êô∫ËÉΩÊ®°ÊãüÊ≥®ÂÖ•Ê®°Âºè (Âü∫‰∫éInjectsOptimizer)")
            success = injector.run_simulation_inject(
                case_id=args.case_id,
                entrypoint=args.entrypoint,
                inject_var=args.inject_var,
                knowledge_path=args.knows,
                max_iterations=args.max_iterations,
                timeout_seconds=args.sim_timeout,
                top_n=args.top_n,
            )
        else:
            # Batch processing for low-accuracy cases
            success = injector.run_batch_simulation_inject(
                accuracy_threshold=args.accuracy_threshold,
                entrypoint=args.entrypoint,
                inject_var=args.inject_var,
                knowledge_path=args.knows,
                max_iterations=args.max_iterations,
                timeout_seconds=args.sim_timeout,
                top_n=args.top_n,
            )
        return 0 if success else 1
    elif args.cross_run_analysis:
        # Cross-run analysis mode
        # If a specific case is specified, do not require max_accuracy (default to 100)
        if not args.max_accuracy and not args.case:
            print("Error: --cross-run-analysis requires --max-accuracy (unless --case is provided).")
            print("Usage:")
            print("  Analyze all cases below threshold: python analyze.py <experiment> --cross-run-analysis --max-accuracy <threshold>")
            print("  Analyze a specific case: python analyze.py <experiment> --cross-run-analysis --case <case_num>")
            print("Example: python analyze.py watsons_baseline --cross-run-analysis --max-accuracy 30")
            return 1

        # If case is specified but max_accuracy is not, use 100 as default (include all cases)
        max_accuracy = args.max_accuracy if args.max_accuracy is not None else (100 if args.case else None)

        success = coordinator.run_cross_run_analysis(
            max_accuracy=max_accuracy,
            report_csv=args.report_csv,
            knowledge_path=args.knows,
            enable_summary=args.summary,
            case=args.case
        )
        return 0 if success else 1
    elif args.analysis or (not args.general and not args.cross_run_analysis and (args.run or args.case or args.summary)):
        # Validate required parameters for summary mode
        if args.summary:
            if not args.run:
                print("Error: --summary requires --run.")
                print("Usage: python analyze.py <experiment> --analysis --run <run_name> --summary")
                return 1
            # Summary mode
            success = coordinator.run_summary_analysis(args.run, knowledge_path=args.knows)
            return 0 if success else 1
        else:
            # Agent execution analysis mode
            if not args.run:
                print("Error: --analysis requires --run.")
                print("Usage:")
                print("  Analyze a single case: python analyze.py <experiment> --analysis --run <run_name> --case <case_num>")
                print("  Analyze all failed cases: python analyze.py <experiment> --analysis --run <run_name>")
                print("  Analyze failed cases only: python analyze.py <experiment> --analysis --run <run_name> --failed-only")
                return 1

            if args.case:
                # Analyze a single case
                success = coordinator.run_execution_analysis(args.run, args.case, knowledge_path=args.knows)
                return 0 if success else 1
            else:
                # Batch analyze cases (failed-only by default)
                success = coordinator.run_batch_execution_analysis(args.run, failed_only=(args.failed_only or True), knowledge_path=args.knows)
                return 0 if success else 1
    else:
        # General analysis mode (default)
        success = coordinator.run_general_analysis()
        return 0 if success else 1


if __name__ == "__main__":
    exit(main())
