#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå™¨

è´Ÿè´£åˆ†ææ™ºèƒ½ä½“çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- é¢„å¤„ç†å®éªŒæ—¥å¿—
- è·å–benchmarkæ•°æ®
- è°ƒç”¨analysis.dphè¿›è¡Œæ‰§è¡Œè¿‡ç¨‹åˆ†æ
- å¯¹æ¯”æ™ºèƒ½ä½“æ‰§è¡Œè½¨è¿¹ä¸é¢„æœŸç»“æœ
"""

import json
import re
import subprocess
import tempfile
from pathlib import Path
from datetime import datetime
import time

from dolphin.core.common.constants import (
    DOLPHIN_VARIABLES_OUTPUT_START,
    DOLPHIN_VARIABLES_OUTPUT_END,
)

try:
    from .base_analyzer import BaseAnalyzer
except ImportError:
    from base_analyzer import BaseAnalyzer


class ExecutionAnalyzer(BaseAnalyzer):
    """æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå™¨"""

    def __init__(self, data_loader):
        """
        åˆå§‹åŒ–æ‰§è¡Œåˆ†æå™¨

        Args:
            data_loader: ExperimentDataLoaderå®ä¾‹
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(data_loader)

    def analyze_execution(
        self, run_name, case_num, save_to_file=True, knowledge_path=None
    ):
        """
        åˆ†ææ™ºèƒ½ä½“åœ¨å•ä¸ªcaseä¸Šçš„æ‰§è¡Œè¿‡ç¨‹

        Args:
            run_name: runåç§°
            case_num: caseç¼–å·
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            æ‰§è¡Œåˆ†æç»“æœ
        """
        print(f"ğŸ” å¼€å§‹åˆ†ææ™ºèƒ½ä½“æ‰§è¡Œè¿‡ç¨‹ - Run: {run_name}, Case: {case_num}")
        if knowledge_path:
            print(f"ğŸ“š åŠ è½½ä¸šåŠ¡çŸ¥è¯†: {knowledge_path}")

        # é¢„å¤„ç†å®éªŒæ—¥å¿—å¹¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        processed_log_path = self._preprocess_execution_log(run_name, case_num)
        if not processed_log_path:
            return None
        print(f"âœ… æˆåŠŸé¢„å¤„ç†æ‰§è¡Œæ—¥å¿—")

        # è·å–benchmarkæ•°æ®
        benchmark = self._get_benchmark_data(case_num)
        if not benchmark:
            return None
        print(f"âœ… æˆåŠŸè·å–benchmarkæ•°æ® (question_id: {benchmark['question_id']})")

        # åŠ è½½ä¸šåŠ¡çŸ¥è¯†
        knowledge_content = ""
        if knowledge_path:
            print(f"ğŸ” æ­£åœ¨åŠ è½½ä¸šåŠ¡çŸ¥è¯†: {knowledge_path}")
            knowledge_content = self._load_knowledge(knowledge_path, run_name)
            if knowledge_content:
                print(f"âœ… æˆåŠŸåŠ è½½ä¸šåŠ¡çŸ¥è¯† ({len(knowledge_content)} å­—ç¬¦)")
            else:
                print("âš ï¸ ä¸šåŠ¡çŸ¥è¯†åŠ è½½å¤±è´¥")

        # æ‰§è¡Œæ™ºèƒ½ä½“åˆ†æ
        print(f"ğŸ”§ è°ƒç”¨ analysis.dphï¼ŒçŸ¥è¯†å†…å®¹é•¿åº¦: {len(knowledge_content)}")
        analysis_result = self._run_execution_analysis(
            processed_log_path, benchmark, knowledge_content
        )
        if not analysis_result:
            return None

        print("âœ… æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå®Œæˆ")

        # ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        if save_to_file and analysis_result:
            self._save_analysis_result(run_name, case_num, analysis_result)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            processed_log_path.unlink()
        except:
            pass

        return analysis_result

    def _preprocess_execution_log(self, run_name, case_num):
        """é¢„å¤„ç†æ™ºèƒ½ä½“æ‰§è¡Œæ—¥å¿—ï¼Œæå–å…³é”®æ‰§è¡Œä¿¡æ¯"""
        # ä½¿ç”¨æ–°çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„æ ¼å¼
        case_num_padded = f"{int(case_num):03d}"
        log_file = (
            self.root_dir
            / "experiments"
            / "env"
            / self.experiment_name
            / run_name
            / "console"
            / f"case_{case_num_padded}.log"
        )

        # å¦‚æœæ–°è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•æ—§è·¯å¾„æ ¼å¼
        if not log_file.exists():
            run_num = run_name.split("_")[-1].lstrip("0") or "0"
            case_num_clean = case_num.lstrip("0") or "0"
            log_file = (
                self.root_dir
                / "experiments"
                / "env"
                / self.experiment_name
                / run_name
                / "log"
                / f"experiment_run_{run_num}_case_{case_num_clean}.log"
            )

        if not log_file.exists():
            print(f"é”™è¯¯: æ‰§è¡Œæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            return None

        try:
            # è¯»å–å®Œæ•´æ‰§è¡Œæ—¥å¿—
            with open(log_file, "r", encoding="utf-8") as f:
                full_content = f.read()

            # æˆªå–åˆ°Final result:ä¹‹å‰çš„ä¸»è¦æ‰§è¡Œè½¨è¿¹
            content = full_content
            final_result_pos = content.find("Final result:")
            if final_result_pos != -1:
                content = content[:final_result_pos]

            content = content.strip()

            # æå–å…³é”®æ‰§è¡Œä¿¡æ¯ä½œä¸ºMETAæ•°æ®
            meta_lines = []
            meta_lines.append("\n\n==== EXECUTION META (extracted) ====")

            # 1) æå–æ™ºèƒ½ä½“æœ€ç»ˆç­”æ¡ˆ
            try:
                ans_match = re.search(
                    r"Final result:\s*\{.*?'answer':\s*'(.*?)',\s*'think'",
                    full_content,
                    re.DOTALL,
                )
                if ans_match:
                    raw_answer = ans_match.group(1)
                    clean_answer = raw_answer.replace("\\n", "\n")
                    meta_lines.append("[agent_answer]\n" + clean_answer.strip())
            except Exception:
                pass

            # 2) æå–æœ€ç»ˆSQLæŸ¥è¯¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                # å»é™¤ANSIé¢œè‰²ç 
                ansi_escape = re.compile(r"\x1B(?:[@-Z\\\\-_]|\[[0-?]*[ -/]*[@-~])")
                no_ansi = ansi_escape.sub("", full_content)

                # åŒ¹é…æœ€åä¸€ä¸ªSQLæŸ¥è¯¢
                sql_matches = list(
                    re.finditer(r'"sql"\s*:\s*"(.*?)"', no_ansi, re.DOTALL)
                )
                if sql_matches:
                    last_sql = sql_matches[-1].group(1)
                    last_sql = last_sql.replace("\\n", "\n")
                    meta_lines.append("[executed_sql]\n" + last_sql.strip())
            except Exception:
                pass

            # 3) æå–å·¥å…·è°ƒç”¨é“¾
            try:
                tool_calls = []
                tool_matches = re.finditer(r"ğŸ› ï¸\s*(\w+):", content)
                for match in tool_matches:
                    tool_calls.append(match.group(1))
                if tool_calls:
                    meta_lines.append("[tool_chain]\n" + " -> ".join(tool_calls))
            except Exception:
                pass

            # 4) æå–æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                think_match = re.search(r"'think':\s*'(.*?)'", full_content, re.DOTALL)
                if think_match:
                    think_content = think_match.group(1).replace("\\n", "\n")
                    # åªä¿ç•™å‰500å­—ç¬¦é¿å…è¿‡é•¿
                    if len(think_content) > 500:
                        think_content = think_content[:500] + "..."
                    meta_lines.append("[agent_thinking]\n" + think_content.strip())
            except Exception:
                pass

            # åˆå¹¶å†…å®¹å’ŒMETAæ•°æ®
            if meta_lines and len(meta_lines) > 1:
                content = content + "\n" + "\n".join(meta_lines)

            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(
                mode="w", encoding="utf-8", delete=False, suffix=".log"
            ) as tmp_file:
                tmp_file.write(content)
                return Path(tmp_file.name)

        except Exception as e:
            print(f"é”™è¯¯: é¢„å¤„ç†æ‰§è¡Œæ—¥å¿—å¤±è´¥: {e}")
            return None

    # _get_benchmark_data method moved to BaseAnalyzer

    def _run_execution_analysis(
        self, execution_log_path, benchmark, knowledge_content=""
    ):
        """è°ƒç”¨analysis.dphè¿›è¡Œæ™ºèƒ½ä½“æ‰§è¡Œåˆ†æ"""
        analysis_log_file = None
        try:
            analysis_file = Path(__file__).parent / "dolphins" / "analysis.dph"
            if not analysis_file.exists():
                print(f"é”™è¯¯: analysis.dphæ–‡ä»¶ä¸å­˜åœ¨: {analysis_file}")
                return None

            # æ„å»ºdolphinå‘½ä»¤
            cmd_parts = [
                str(self.dolphin_cmd),
                "--folder",
                Path(__file__).parent / "dolphins",
                "--agent",
                "analysis",
                "--exp_log_path",
                str(execution_log_path),
                "--benchmark",
                json.dumps(benchmark, ensure_ascii=False),
                "--busi_knowledge",
                knowledge_content,
                "--output-variables",
                "analysis_result",
            ]

            # åˆ›å»ºä¸´æ—¶æ—¥å¿—æ–‡ä»¶
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            analysis_log_file = self.reports_dir / f"execution_analysis_{ts}.log"

            print("ğŸ”§ æ‰§è¡Œæ™ºèƒ½ä½“åˆ†æ...")

            # æ‰§è¡Œåˆ†æå‘½ä»¤
            with open(analysis_log_file, "w", encoding="utf-8") as log_f:
                try:
                    result = subprocess.run(
                        cmd_parts,
                        stdout=log_f,
                        stderr=subprocess.STDOUT,
                        cwd=str(self.root_dir),
                        timeout=500,
                    )
                    exit_code = result.returncode
                except Exception as e:
                    exit_code = 1
                    print(f"Warning: Failed to run analysis command: {e}")
                    return None

            # ç­‰å¾…æ—¥å¿—æ–‡ä»¶å†™å…¥å®Œæˆ
            time.sleep(0.1)

            if exit_code != 0:
                print(f"é”™è¯¯: æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå¤±è´¥ï¼Œé€€å‡ºç : {exit_code}")
                return None

            # è¯»å–åˆ†æç»“æœ
            try:
                with open(analysis_log_file, "r", encoding="utf-8") as f:
                    log_content = f.read()

                # æå–åˆ†æç»“æœ
                extracted = self._extract_analysis_result(log_content)
                if extracted:
                    # æˆåŠŸæå–ç»“æœï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        analysis_log_file.unlink(missing_ok=True)
                    except:
                        pass
                    return extracted

                print("Warning: Failed to extract analysis result from log")
                return "æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå®Œæˆï¼Œä½†æ— æ³•æå–åˆ†æç»“æœã€‚"

            except Exception as e:
                print(f"Warning: Failed to read analysis log file: {e}")
                return None

        except Exception as e:
            print(f"é”™è¯¯: æ‰§è¡Œæ™ºèƒ½ä½“åˆ†æå¤±è´¥: {e}")
            return None
        finally:
            # ç¡®ä¿ä¸´æ—¶æ—¥å¿—æ–‡ä»¶è¢«æ¸…ç†
            if analysis_log_file and analysis_log_file.exists():
                try:
                    analysis_log_file.unlink(missing_ok=True)
                except:
                    pass

    def _extract_analysis_result(self, log_content: str):
        """ä»DOLPHIN_VARIABLES_OUTPUTæ ‡è®°ä¸­æå–åˆ†æç»“æœ"""
        if not log_content:
            return None

        try:
            # ä½¿ç”¨åŸºç±»çš„é€šç”¨æ–¹æ³•æå–å˜é‡è¾“å‡ºéƒ¨åˆ†
            variables_section = self._extract_result_from_log(
                log_content,
                DOLPHIN_VARIABLES_OUTPUT_START,
                DOLPHIN_VARIABLES_OUTPUT_END,
            )
            if not variables_section:
                return None

            # è§£æJSON
            variables = json.loads(variables_section)

            # æå–åˆ†æç»“æœ
            analysis_result = variables.get("analysis_result", {}).get("answer")
            if isinstance(analysis_result, str) and analysis_result.strip():
                return analysis_result.strip()
            return None

        except Exception as e:
            print(f"Warning: Failed to extract analysis result from log: {e}")
            return None

    # _load_knowledge method moved to BaseAnalyzer

    def _save_analysis_result(self, run_name, case_num, analysis_result):
        """ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        # ä½¿ç”¨åŸºç±»æ–¹æ³•æŸ¥æ‰¾runç›®å½•
        run_dir = self._find_run_directory(run_name)
        if not run_dir:
            return

        # åˆ›å»º analysis ç›®å½•
        analysis_dir = run_dir / "analysis"
        analysis_dir.mkdir(exist_ok=True)

        # ä¿å­˜åˆ†æç»“æœ
        case_num_padded = f"{int(case_num):03d}"
        result_file = analysis_dir / f"case_{case_num_padded}.txt"

        try:
            with open(result_file, "w", encoding="utf-8") as f:
                f.write(f"=== Analysis Result for Case {case_num_padded} ===\n")
                f.write(f"Run: {run_name}\n")
                f.write(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("\n" + "=" * 60 + "\n\n")
                f.write("===ANALYSIS_START===\n")
                f.write(analysis_result)
                f.write("\n===ANALYSIS_END===\n")
            print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        except Exception as e:
            print(f"Warning: ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")

    def load_analysis_result(self, run_name, case_num):
        """åŠ è½½å·²ä¿å­˜çš„åˆ†æç»“æœ"""
        run_dir = self._find_run_directory(run_name)
        if not run_dir:
            return None

        # æŸ¥æ‰¾åˆ†æç»“æœæ–‡ä»¶
        case_num_padded = f"{int(case_num):03d}"
        result_file = run_dir / "analysis" / f"case_{case_num_padded}.txt"

        if not result_file.exists():
            return None

        try:
            with open(result_file, "r", encoding="utf-8") as f:
                content = f.read()
                # é¦–å…ˆå°è¯•ä»===ANALYSIS_START===å’Œ===ANALYSIS_END===ä¸­æå–
                start_marker = "===ANALYSIS_START==="
                end_marker = "===ANALYSIS_END==="
                start_pos = content.find(start_marker)
                if start_pos != -1:
                    end_pos = content.find(end_marker, start_pos)
                    if end_pos != -1:
                        # æå–æ ‡è®°ä¹‹é—´çš„å†…å®¹
                        return content[start_pos + len(start_marker) : end_pos].strip()

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°ï¼Œä½¿ç”¨æ—§çš„æ–¹å¼
                separator = "=" * 60 + "\n\n"
                if separator in content:
                    return content.split(separator, 1)[1]
                return content
        except Exception as e:
            print(f"Warning: åŠ è½½åˆ†æç»“æœå¤±è´¥: {e}")
            return None
