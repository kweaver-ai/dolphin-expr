#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Summaryåˆ†æå™¨

è´Ÿè´£è°ƒç”¨summary.dphåˆ†ææŒ‡å®šrunç›®å½•ä¸‹çš„analysisç»“æœï¼ŒåŒ…æ‹¬ï¼š
- è¯»å–runç›®å½•ä¸‹çš„analysisæ–‡ä»¶å¤¹å†…å®¹
- è°ƒç”¨summary.dphè¿›è¡Œç»¼åˆåˆ†æ
- å°†åˆ†æç»“æœå†™å…¥æ–‡ä»¶
"""

import json
import subprocess
import tempfile
from pathlib import Path
from datetime import datetime
import time

try:
    from .base_analyzer import BaseAnalyzer
except ImportError:
    from base_analyzer import BaseAnalyzer


class SummaryAnalyzer(BaseAnalyzer):
    """Summaryåˆ†æå™¨"""

    def __init__(self, data_loader):
        """
        åˆå§‹åŒ–Summaryåˆ†æå™¨

        Args:
            data_loader: ExperimentDataLoaderå®ä¾‹
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(data_loader)

    def analyze_summary(self, run_name, knowledge_path=None):
        """
        å¯¹æŒ‡å®šrunçš„analysisç»“æœè¿›è¡Œsummaryåˆ†æ

        Args:
            run_name: runåç§°
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            summaryåˆ†æç»“æœ
        """
        print(f"ğŸ” å¼€å§‹è¿›è¡ŒSummaryåˆ†æ - Run: {run_name}")

        # æ„å»ºanalysisæ–‡ä»¶å¤¹è·¯å¾„
        run_path = (
            self.root_dir / "experiments" / "env" / self.experiment_name / run_name
        )
        analysis_path = run_path / "analysis"

        if not analysis_path.exists():
            print(f"é”™è¯¯: analysisç›®å½•ä¸å­˜åœ¨: {analysis_path}")
            return None

        print(f"âœ… æ‰¾åˆ°analysisç›®å½•: {analysis_path}")

        # åŠ è½½ä¸šåŠ¡çŸ¥è¯†
        knowledge_content = ""
        if knowledge_path:
            knowledge_content = self._load_knowledge(knowledge_path, run_name)
            if knowledge_content:
                print(f"âœ… æˆåŠŸåŠ è½½ä¸šåŠ¡çŸ¥è¯† ({len(knowledge_content)} å­—ç¬¦)")
            else:
                print("âš ï¸ ä¸šåŠ¡çŸ¥è¯†åŠ è½½å¤±è´¥")

        # æ‰§è¡Œsummaryåˆ†æ
        summary_result = self._run_summary_analysis(analysis_path, knowledge_content)
        if not summary_result:
            return None

        print("âœ… Summaryåˆ†æå®Œæˆ")

        # å†™å…¥ç»“æœæ–‡ä»¶
        result_file = self._write_summary_result(run_name, summary_result)
        if result_file:
            print(f"âœ… Summaryç»“æœå·²å†™å…¥: {result_file}")

        return summary_result

    def _run_summary_analysis(self, folder_path, knowledge_content=""):
        """è°ƒç”¨summary.dphè¿›è¡Œåˆ†æ"""
        summary_log_file = None
        try:
            summary_file = Path(__file__).parent / "dolphins" / "summary.dph"
            if not summary_file.exists():
                print(f"é”™è¯¯: summary.dphæ–‡ä»¶ä¸å­˜åœ¨: {summary_file}")
                return None

            # åœ¨å¤–éƒ¨è§£æåˆ†ææ–‡ä»¶å†…å®¹
            analysis_content = self._parse_analysis_files(folder_path)
            if not analysis_content:
                print(f"é”™è¯¯: æ— æ³•ä»åˆ†æç›®å½•æå–å†…å®¹: {folder_path}")
                return None

            print(f"âœ… æˆåŠŸæå– {len(analysis_content)} å­—ç¬¦çš„åˆ†æå†…å®¹")

            # æ„å»ºdolphinå‘½ä»¤ - ä½¿ç”¨analysis_contentè€Œä¸æ˜¯folder_path
            cmd_parts = [
                str(self.dolphin_cmd),
                "--folder",
                Path(__file__).parent / "dolphins",
                "--agent",
                "summary",
                "--analysis_content",
                analysis_content,
                "--busi_knowledge",
                knowledge_content,
                "--output-variables",
                "suggestions",
            ]

            # åˆ›å»ºä¸´æ—¶æ—¥å¿—æ–‡ä»¶
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            summary_log_file = self.reports_dir / f"summary_analysis_{ts}.log"

            print("ğŸ”§ æ‰§è¡ŒSummaryåˆ†æ...")

            # æ‰§è¡Œåˆ†æå‘½ä»¤
            with open(summary_log_file, "w", encoding="utf-8") as log_f:
                try:
                    result = subprocess.run(
                        cmd_parts,
                        stdout=log_f,
                        stderr=subprocess.STDOUT,
                        cwd=str(self.root_dir),
                        timeout=500,
                    )
                    exit_code = result.returncode
                except Exception as e:
                    exit_code = 1
                    print(f"Warning: Failed to run summary command: {e}")
                    return None

            # ç­‰å¾…æ—¥å¿—æ–‡ä»¶å†™å…¥å®Œæˆ
            time.sleep(0.1)

            if exit_code != 0:
                print(f"é”™è¯¯: Summaryåˆ†æå¤±è´¥ï¼Œé€€å‡ºç : {exit_code}")
                return None

            # è¯»å–åˆ†æç»“æœ
            try:
                with open(summary_log_file, "r", encoding="utf-8") as f:
                    log_content = f.read()

                # æå–åˆ†æç»“æœ
                extracted = self._extract_summary_result(log_content)
                if extracted:
                    # æˆåŠŸæå–ç»“æœï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        summary_log_file.unlink(missing_ok=True)
                    except:
                        pass
                    return extracted

                print("Warning: Failed to extract summary result from log")
                return "Summaryåˆ†æå®Œæˆï¼Œä½†æ— æ³•æå–åˆ†æç»“æœã€‚"

            except Exception as e:
                print(f"Warning: Failed to read summary log file: {e}")
                return None

        except Exception as e:
            print(f"é”™è¯¯: æ‰§è¡ŒSummaryåˆ†æå¤±è´¥: {e}")
            return None
        finally:
            # ç¡®ä¿ä¸´æ—¶æ—¥å¿—æ–‡ä»¶è¢«æ¸…ç†
            if summary_log_file and summary_log_file.exists():
                try:
                    summary_log_file.unlink(missing_ok=True)
                except:
                    pass

    def _parse_analysis_files(self, folder_path):
        """
        è§£æåˆ†ææ–‡ä»¶å¤¹ä¸­çš„åˆ†æå†…å®¹

        Args:
            folder_path: åˆ†ææ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            è§£æå‡ºçš„åˆ†æå†…å®¹å­—ç¬¦ä¸²
        """
        try:
            folder_path = Path(folder_path)
            if not folder_path.exists() or not folder_path.is_dir():
                print(f"é”™è¯¯: åˆ†æç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {folder_path}")
                return None

            analysis_contents = []
            analysis_files = []

            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„åˆ†æç»“æœæ–‡ä»¶
            for file_path in folder_path.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in [
                    ".txt",
                    ".log",
                    ".md",
                ]:
                    analysis_files.append(file_path)

            if not analysis_files:
                print(f"è­¦å‘Š: åœ¨ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†ææ–‡ä»¶")
                return None

            print(f"ğŸ” æ‰¾åˆ° {len(analysis_files)} ä¸ªåˆ†ææ–‡ä»¶")

            # è§£ææ¯ä¸ªæ–‡ä»¶ä¸­çš„åˆ†æå†…å®¹
            for file_path in sorted(analysis_files):
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        file_content = f.read()

                    # æŸ¥æ‰¾ ===ANALYSIS_START=== å’Œ ===ANALYSIS_END=== ä¹‹é—´çš„å†…å®¹
                    extracted_content = self._extract_analysis_content(
                        file_content, file_path.name
                    )
                    if extracted_content:
                        analysis_contents.append(extracted_content)

                except Exception as e:
                    print(f"è­¦å‘Š: è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                    continue

            if not analysis_contents:
                print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æå†…å®¹")
                return None

            # å°†æ‰€æœ‰åˆ†æå†…å®¹åˆå¹¶
            combined_content = "\n\n" + "=" * 60 + "\n\n".join(analysis_contents)
            return combined_content

        except Exception as e:
            print(f"é”™è¯¯: è§£æåˆ†ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def _extract_analysis_content(self, file_content, file_name):
        """
        ä»æ–‡ä»¶å†…å®¹ä¸­æå– ===ANALYSIS_START=== å’Œ ===ANALYSIS_END=== ä¹‹é—´çš„å†…å®¹

        Args:
            file_content: æ–‡ä»¶å†…å®¹
            file_name: æ–‡ä»¶åï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            æå–çš„åˆ†æå†…å®¹
        """
        try:
            start_marker = "===ANALYSIS_START==="
            end_marker = "===ANALYSIS_END==="

            start_pos = file_content.find(start_marker)
            if start_pos == -1:
                print(f"è­¦å‘Š: åœ¨ {file_name} ä¸­æœªæ‰¾åˆ°å¼€å§‹æ ‡è®° {start_marker}")
                return None

            end_pos = file_content.find(end_marker, start_pos)
            if end_pos == -1:
                print(f"è­¦å‘Š: åœ¨ {file_name} ä¸­æœªæ‰¾åˆ°ç»“æŸæ ‡è®° {end_marker}")
                return None

            # æå–æ ‡è®°ä¹‹é—´çš„å†…å®¹
            content_start = start_pos + len(start_marker)
            extracted_content = file_content[content_start:end_pos].strip()

            if not extracted_content:
                print(f"è­¦å‘Š: åœ¨ {file_name} ä¸­æå–çš„åˆ†æå†…å®¹ä¸ºç©º")
                return None

            # æ·»åŠ æ–‡ä»¶æ ‡è¯†
            formatted_content = f"=== æ¥è‡ªæ–‡ä»¶: {file_name} ===\n{extracted_content}"
            print(f"âœ… ä» {file_name} æå–äº† {len(extracted_content)} å­—ç¬¦çš„åˆ†æå†…å®¹")

            return formatted_content

        except Exception as e:
            print(f"é”™è¯¯: ä» {file_name} æå–åˆ†æå†…å®¹æ—¶å‡ºé”™: {e}")
            return None

    def _extract_summary_result(self, log_content: str):
        """ä»DOLPHIN_VARIABLES_OUTPUTæ ‡è®°ä¸­æå–summaryç»“æœ"""
        if not log_content:
            return None

        try:
            # æŸ¥æ‰¾å˜é‡è¾“å‡ºåŒºåŸŸ
            start_marker = "=== DOLPHIN_VARIABLES_OUTPUT_START ==="
            end_marker = "=== DOLPHIN_VARIABLES_OUTPUT_END ==="

            start_pos = log_content.find(start_marker)
            if start_pos == -1:
                return None

            end_pos = log_content.find(end_marker, start_pos)
            if end_pos == -1:
                return None

            # æå–JSONå†…å®¹
            json_start = start_pos + len(start_marker)
            json_content = log_content[json_start:end_pos].strip()

            # è§£æJSON
            variables = json.loads(json_content)

            # æå–suggestionsç»“æœ
            suggestions = variables.get("suggestions", {}).get("answer")
            if isinstance(suggestions, str) and suggestions.strip():
                return suggestions.strip()
            return None

        except Exception as e:
            print(f"Warning: Failed to extract summary result from log: {e}")
            return None

    # _load_knowledge method moved to BaseAnalyzer

    def _write_summary_result(self, run_name, summary_result):
        """å°†summaryç»“æœå†™å…¥æ–‡ä»¶"""
        try:
            run_path = self._find_run_directory(run_name)
            if not run_path:
                print(f"Warning: æ— æ³•æ‰¾åˆ°runç›®å½•ä»¥ä¿å­˜summaryç»“æœ")
                return None

            summary_file = run_path / "summary_result.txt"

            # å†™å…¥ç»“æœ
            with open(summary_file, "w", encoding="utf-8") as f:
                f.write("=" * 60 + "\n")
                f.write(f"Summary Analysis Result - {run_name}\n")
                f.write(
                    f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write("=" * 60 + "\n\n")
                f.write(summary_result)
                f.write("\n\n")

            return summary_file

        except Exception as e:
            print(f"é”™è¯¯: å†™å…¥summaryç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            return None
