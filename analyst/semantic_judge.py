#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SemanticJudge: åŸºäºŽè·¨ run çš„å¤±è´¥åˆ†æžï¼Œäº§å‡ºâ€œè¯­ä¹‰æ¢¯åº¦â€è¯Šæ–­ä¸Žå€™é€‰æ³¨å…¥ã€‚

å®žçŽ°æ–¹å¼ï¼šå¤ç”¨ dolphin CLI ä¸Žä¸“ç”¨ agentï¼ˆsemantic_judge.dphï¼‰ï¼Œ
è¾“å…¥ analysis_contentï¼ˆè·¨ run æ±‡æ€»ï¼‰ã€expected çš„è„±æ•ç‰ˆæœ¬ã€actual è¾“å‡ºä¸Žå¯é€‰ä¸šåŠ¡çŸ¥è¯†ï¼Œ
è¾“å‡ºç»“æž„åŒ– JSONï¼šscoreã€error_typesã€action_vectorã€candidate_injectsã€rationale ç­‰ã€‚
"""

from __future__ import annotations

import json
import re
from pathlib import Path
from datetime import datetime
import subprocess

from dolphin.core.common.constants import (
    DOLPHIN_VARIABLES_OUTPUT_START,
    DOLPHIN_VARIABLES_OUTPUT_END,
)


class SemanticJudge:
    def __init__(self, data_loader, simulation_logs_dir=None):
        """
        Args:
            data_loader: ExperimentAnalyzer å®žä¾‹ï¼ˆä½œä¸ºæ•°æ®ä¸Šä¸‹æ–‡ä¸Ž dolphin å…¥å£ï¼‰
            simulation_logs_dir: å¯é€‰çš„simulation_logsç›®å½•è·¯å¾„ï¼Œå¦‚æžœæä¾›åˆ™ä¼˜å…ˆä½¿ç”¨
        """
        self.data_loader = data_loader
        self.root_dir = data_loader.root_dir
        self.dolphin_cmd = data_loader.dolphin_cmd
        self.reports_dir = data_loader.reports_dir

        # å¦‚æžœæä¾›äº†simulation_logs_dirï¼Œä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™å›žé€€åˆ°reports_dir
        # è¿™æ ·å¯ä»¥ä¿æŒå‘åŽå…¼å®¹æ€§ï¼ŒåŒæ—¶å…è®¸æ›´å¥½çš„æ—¥å¿—ç»„ç»‡
        if simulation_logs_dir:
            # ç¡®ä¿simulation_logsç›®å½•å­˜åœ¨
            Path(simulation_logs_dir).mkdir(exist_ok=True)
            self.log_dir = simulation_logs_dir
            print(f"ðŸ”§ SemanticJudgeæ—¥å¿—å°†ä¿å­˜åˆ°: {simulation_logs_dir}")
        else:
            self.log_dir = self.reports_dir
            print(f"ðŸ”§ SemanticJudgeæ—¥å¿—å°†ä¿å­˜åˆ°: {self.reports_dir} (å‘åŽå…¼å®¹æ¨¡å¼)")

    @staticmethod
    def redact_expected(expected: str) -> str:
        """å¯¹æœŸæœ›ç­”æ¡ˆåšè„±æ•ï¼Œé¿å…æ³„éœ²ç²¾ç¡®å®žä½“/æ•°å€¼ã€‚

        - ç™¾åˆ†æ¯” -> [PCT]
        - è¿žç»­æ•°å­—ï¼ˆ>=2ä½ï¼‰ -> [NUM]
        - å•å­—æ¯/é€‰é¡¹ï¼ˆA/B/Cç­‰ï¼‰ä¿ç•™ï¼Œä½†ä¸åº”è¢«æ¨¡åž‹å¼•ç”¨ä¸ºç­”æ¡ˆ
        """
        if not expected:
            return ""
        s = str(expected)
        s = re.sub(r"\d+%", "[PCT]", s)
        s = re.sub(r"\d{2,}", "[NUM]", s)
        return s

    def evaluate(
        self, analysis_content: str, expected: str, actual: str, knowledge: str = ""
    ) -> dict | None:
        """
        è¿è¡Œè¯­ä¹‰è£åˆ¤ï¼Œè¿”å›žè¯Šæ–­ JSONã€‚
        è¿”å›žå­—æ®µå»ºè®®ï¼š
          - score: 0~1
          - correct: bool
          - error_types: list[str]
          - missing_constraints: list[str]
          - action_vector: list[str]
          - candidate_injects: list[str]
          - rationale: str
        """
        judge_file = Path(__file__).parent / "dolphins" / "semantic_judge.dph"
        if not judge_file.exists():
            raise FileNotFoundError(f"semantic_judge.dph ä¸å­˜åœ¨: {judge_file}")

        expected_redacted = self.redact_expected(expected)

        cmd_parts = [
            str(self.dolphin_cmd),
            "--folder",
            Path(__file__).parent / "dolphins",
            "--agent",
            "semantic_judge",
            "--analysis_content",
            analysis_content or "",
            "--expected_redacted",
            expected_redacted or "",
            "--actual_output",
            actual or "",
            "--busi_knowledge",
            knowledge or "",
            "--output-variables",
            "gradient",
        ]

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.log_dir / f"semantic_judge_{ts}.log"

        with open(log_file, "w", encoding="utf-8") as f:
            result = subprocess.run(
                cmd_parts,
                stdout=f,
                stderr=subprocess.STDOUT,
                cwd=str(self.root_dir),
                text=True,
            )

        if result.returncode != 0:
            # Do not fallback; surface failure to caller
            return None

        # è§£æžæ—¥å¿—ä¸­çš„ DOLPHIN_VARIABLES_OUTPUT åŒºåŸŸ
        try:
            with open(log_file, "r", encoding="utf-8") as rf:
                output = rf.read()
            gradient_str = self._extract_var_from_log(output, var_name="gradient")
            if not gradient_str:
                return None
            gradient = json.loads(gradient_str)
            # åŸºç¡€å­—æ®µå®¹é”™
            gradient.setdefault("score", 0.0)
            gradient.setdefault("correct", False)
            gradient.setdefault("error_types", [])
            gradient.setdefault("missing_constraints", [])
            gradient.setdefault("action_vector", [])
            gradient.setdefault("candidate_injects", [])
            gradient.setdefault("rationale", "")
            return gradient
        except Exception:
            return None

    def evaluate_enhanced(
        self, evaluate_context: dict, knowledge: str = ""
    ) -> dict | None:
        """
        å¢žå¼ºç‰ˆè¯­ä¹‰è¯„ä¼°ï¼ŒæŽ¥æ”¶å®Œæ•´çš„è¯„ä¼°ä¸Šä¸‹æ–‡
        """
        judge_file = Path(__file__).parent / "dolphins" / "semantic_judge.dph"
        if not judge_file.exists():
            raise FileNotFoundError(f"semantic_judge.dph ä¸å­˜åœ¨: {judge_file}")

        # æå–å…³é”®ä¿¡æ¯
        analysis_content = evaluate_context.get("analysis_content", "")
        predicted_result = evaluate_context.get("predicted_result", "")
        benchmark_context = self._prepare_benchmark_context(evaluate_context)

        # æå–æœŸæœ›ç­”æ¡ˆä¿¡æ¯
        expected_info = evaluate_context.get("expected_info", {})
        expected_redacted = self.redact_expected(expected_info.get("raw_expected", ""))

        cmd_parts = [
            str(self.dolphin_cmd),
            "--folder",
            Path(__file__).parent / "dolphins",
            "--agent",
            "semantic_judge",
            "--analysis_content",
            analysis_content or "",
            "--benchmark_context",
            benchmark_context or "",
            "--expected_redacted",
            expected_redacted or "",
            "--expected_info",
            json.dumps(expected_info, ensure_ascii=False),
            "--actual_output",
            predicted_result or "",
            "--busi_knowledge",
            knowledge or "",
            "--output-variables",
            "gradient",
        ]

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = self.log_dir / f"semantic_judge_enhanced_{ts}.log"

        with open(log_file, "w", encoding="utf-8") as f:
            result = subprocess.run(
                cmd_parts,
                stdout=f,
                stderr=subprocess.STDOUT,
                cwd=str(self.root_dir),
                text=True,
            )

        if result.returncode != 0:
            return None

        # è§£æžæ—¥å¿—ä¸­çš„ DOLPHIN_VARIABLES_OUTPUT åŒºåŸŸ
        try:
            with open(log_file, "r", encoding="utf-8") as rf:
                output = rf.read()
            gradient_str = self._extract_var_from_log(output, var_name="gradient")
            if not gradient_str:
                return None
            gradient = json.loads(gradient_str)
            # åŸºç¡€å­—æ®µå®¹é”™
            gradient.setdefault("score", 0.0)
            gradient.setdefault("correct", False)
            gradient.setdefault("error_types", [])
            gradient.setdefault("missing_constraints", [])
            gradient.setdefault("action_vector", [])
            gradient.setdefault("candidate_injects", [])
            gradient.setdefault("rationale", "")
            return gradient
        except Exception:
            return None

    def _prepare_benchmark_context(self, evaluate_context: dict) -> str:
        return json.dumps(
            evaluate_context.get("benchmark_item", {}), ensure_ascii=False
        )

    @staticmethod
    def _extract_var_from_log(log_content: str, var_name: str) -> str | None:
        start_marker = DOLPHIN_VARIABLES_OUTPUT_START
        end_marker = DOLPHIN_VARIABLES_OUTPUT_END
        s = log_content.find(start_marker)
        if s == -1:
            return None
        e = log_content.find(end_marker, s)
        if e == -1:
            return None
        json_content = log_content[s + len(start_marker) : e].strip()
        try:
            variables = json.loads(json_content)
        except Exception:
            return None
        val = variables.get(var_name)
        # If the variable is already a structured object (dict/list),
        # return its JSON string so the caller can json.loads it.
        if isinstance(val, (dict, list)):
            try:
                return json.dumps(val, ensure_ascii=False)
            except Exception:
                return None
        if isinstance(val, str):
            return val
        return None
