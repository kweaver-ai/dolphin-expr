#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒåˆ†æåè°ƒå™¨

è´Ÿè´£åè°ƒä¸åŒçš„åˆ†ææ¨¡å—ï¼š
- GeneralReporter: æ€»ä½“æŠ¥å‘Šç”Ÿæˆ
- ExecutionAnalyzer: æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æ
- ExperimentAnalyzer: æ•°æ®åŠ è½½å’Œå¤„ç†ï¼ˆé‡ç”¨ç°æœ‰é€»è¾‘ï¼‰
"""

import argparse
import os
import sys
import json
import shlex
import time
import yaml
from pathlib import Path
from datetime import datetime

# å¯¼å…¥åˆ†ææ¨¡å—
from experiment_analyzer import ExperimentAnalyzer
from general_reporter import GeneralReporter
from execution_analyzer import ExecutionAnalyzer
from summary_analyzer import SummaryAnalyzer
from simulation_inject import SimulationInjector


class ExperimentCoordinator:
    """å®éªŒåˆ†æåè°ƒå™¨"""

    def __init__(self, experiment_path):
        """
        åˆå§‹åŒ–åè°ƒå™¨

        Args:
            experiment_path: å®éªŒç›®å½•è·¯å¾„
        """
        self.experiment_path = Path(experiment_path)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆé‡ç”¨ç°æœ‰çš„ExperimentAnalyzerä½œä¸ºæ•°æ®åŠ è½½å™¨ï¼‰
        self.data_loader = ExperimentAnalyzer(experiment_path)

        # åˆ›å»ºåŠŸèƒ½æ¨¡å—
        self.general_reporter = GeneralReporter(self.data_loader)
        self.execution_analyzer = ExecutionAnalyzer(self.data_loader)
        self.summary_analyzer = SummaryAnalyzer(self.data_loader)
        # è®°å½•æœ¬æ¬¡æ¨¡æ‹Ÿæ‰€ä½¿ç”¨çš„benchmarkç›®å½•ï¼ˆç”¨äºåŠ è½½è‡ªå®šä¹‰è½¬æ¢/æ¯”è¾ƒé€»è¾‘ï¼‰
        self._benchmark_dir = None

    def run_general_analysis(self):
        """è¿è¡Œæ€»ä½“åˆ†æå¹¶ç”ŸæˆæŠ¥å‘Š"""
        print("ğŸ” å¯åŠ¨æ€»ä½“åˆ†ææ¨¡å¼...")

        # åŠ è½½å®éªŒæ•°æ®
        if not self.data_loader.load_experiment_data():
            print("é”™è¯¯: æ— æ³•åŠ è½½å®éªŒæ•°æ®")
            return False

        # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
        try:
            report_path, csv_path = self.general_reporter.generate_report()
            return True
        except Exception as e:
            print(f"é”™è¯¯: ç”Ÿæˆæ€»ä½“æŠ¥å‘Šæ—¶å‡ºç°å¼‚å¸¸: {e}")
            import traceback

            traceback.print_exc()
            return False

    def run_execution_analysis(self, run_name, case_num):
        """è¿è¡Œæ™ºèƒ½ä½“æ‰§è¡Œåˆ†æ"""
        print("ğŸ” å¯åŠ¨æ™ºèƒ½ä½“æ‰§è¡Œåˆ†ææ¨¡å¼...")

        # æ‰§è¡Œæ™ºèƒ½ä½“åˆ†æ
        analysis_result = self.execution_analyzer.analyze_execution(run_name, case_num)
        if analysis_result:
            print("\n" + "=" * 60)
            print("ğŸ“‹ æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æç»“æœ:")
            print("=" * 60)
            print("===ANALYSIS_START===")
            print(analysis_result)
            print("===ANALYSIS_END===")
            print("=" * 60)
            return True
        else:
            print("é”™è¯¯: æ™ºèƒ½ä½“æ‰§è¡Œåˆ†æå¤±è´¥")
            return False

    def run_summary_analysis(self, run_name, knowledge_path=None):
        """è¿è¡Œsummaryåˆ†æ"""
        print("ğŸ” å¯åŠ¨Summaryåˆ†ææ¨¡å¼...")
        if knowledge_path:
            print(f"ğŸ“š ä½¿ç”¨ä¸šåŠ¡çŸ¥è¯†: {knowledge_path}")

        # æ‰§è¡Œsummaryåˆ†æ
        summary_result = self.summary_analyzer.analyze_summary(
            run_name, knowledge_path=knowledge_path
        )
        if summary_result:
            print("\n" + "=" * 60)
            print("ğŸ“‹ Summaryåˆ†æç»“æœ:")
            print("=" * 60)
            print("===SUMMARY_START===")
            print(summary_result)
            print("===SUMMARY_END===")
            print("=" * 60)
            return True
        else:
            print("é”™è¯¯: Summaryåˆ†æå¤±è´¥")
            return False

    def run_cross_run_analysis(
        self,
        max_accuracy,
        report_csv=None,
        knowledge_path=None,
        enable_summary=False,
        case=None,
    ):
        """
        è¿è¡Œè·¨runåˆ†ææ¨¡å¼ï¼Œç­›é€‰æ­£ç¡®ç‡ä½äºé˜ˆå€¼çš„casesè¿›è¡Œåˆ†æ

        Args:
            max_accuracy: æœ€é«˜æ­£ç¡®ç‡é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
            report_csv: general report CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„
            enable_summary: æ˜¯å¦åœ¨åˆ†æå®Œæˆåç”Ÿæˆæ±‡æ€»åˆ†æ

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        import pandas as pd
        from pathlib import Path

        print(f"ğŸ” å¯åŠ¨è·¨runåˆ†ææ¨¡å¼ - æ­£ç¡®ç‡é˜ˆå€¼: {max_accuracy}%")
        if case:
            print(f"ğŸ¯ ä»…åˆ†ææŒ‡å®šçš„ Case: {case}")
        if knowledge_path:
            print(f"ğŸ“š ä½¿ç”¨ä¸šåŠ¡çŸ¥è¯†: {knowledge_path}")
        if enable_summary:
            print("ğŸ“‹ å°†åœ¨åˆ†æå®Œæˆåç”Ÿæˆè·¨runæ±‡æ€»æŠ¥å‘Š")

        # è·å–CSVæ–‡ä»¶è·¯å¾„
        if report_csv:
            csv_path = Path(report_csv)
        else:
            # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„general report CSV - ç°åœ¨åœ¨å®éªŒç›®å½•çš„reportsæ–‡ä»¶å¤¹ä¸­
            reports_dir = self.experiment_path / "reports"
            if not reports_dir.exists():
                print(f"é”™è¯¯: æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨: {reports_dir}")
                print(f"è¯·å…ˆè¿è¡Œ --general ç”ŸæˆæŠ¥å‘Š")
                return False

            csv_files = list(
                reports_dir.glob(f"{self.experiment_path.name}_general_report_*.csv")
            )
            if not csv_files:
                print(f"é”™è¯¯: æœªæ‰¾åˆ°general report CSVæ–‡ä»¶")
                print(f"æœç´¢è·¯å¾„: {reports_dir}")
                print(f"è¯·å…ˆè¿è¡Œ --general ç”ŸæˆæŠ¥å‘Š")
                return False
            csv_path = max(csv_files, key=lambda f: f.stat().st_mtime)
            print(f"ğŸ“Š ä½¿ç”¨æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶: {csv_path.name}")

        # è¯»å–CSVæ–‡ä»¶
        try:
            df = pd.read_csv(csv_path, encoding="utf-8")
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•´ä½“æ­£ç¡®ç‡åˆ—
        if "æ•´ä½“æ­£ç¡®ç‡" not in df.columns:
            print("è­¦å‘Š: CSVæ–‡ä»¶ä¸­æ²¡æœ‰'æ•´ä½“æ­£ç¡®ç‡'åˆ—ï¼Œå°†æ ¹æ®ç°æœ‰æ•°æ®è®¡ç®—")
            # è®¡ç®—æ•´ä½“æ­£ç¡®ç‡
            run_cols = [col for col in df.columns if col.startswith("run_")]
            if not run_cols:
                print("é”™è¯¯: æ‰¾ä¸åˆ°runåˆ—")
                return False

            accuracies = []
            for _, row in df.iterrows():
                correct_count = sum(1 for col in run_cols if row[col] == "âœ“")
                total_count = sum(1 for col in run_cols if row[col] in ["âœ“", "âœ—"])
                if total_count > 0:
                    accuracy = correct_count / total_count * 100
                    accuracies.append(accuracy)
                else:
                    accuracies.append(None)
            df["æ•´ä½“æ­£ç¡®ç‡"] = [
                f"{acc:.1f}%" if acc is not None else "N/A" for acc in accuracies
            ]

        # è§£æå¯é€‰çš„å•ä¸ª case è¿‡æ»¤ï¼ˆæ”¯æŒ 1 / 001 / case_001ï¼‰
        def _parse_case_to_index(case_str):
            try:
                s = case_str.strip().lower()
                for prefix in ["case_", "test_"]:
                    if s.startswith(prefix):
                        s = s[len(prefix) :]
                        break
                # å»æ‰å‰å¯¼é›¶
                s = s.lstrip("0") or "0"
                return int(s)
            except Exception:
                # å…¼å®¹ç›´æ¥ä»æ—¥å¿—å°¾éƒ¨çš„ Final result æ–‡æœ¬ä¸­è§£æ
                try:
                    import re

                    m = re.search(
                        r"Final result: .*?'answer':\s*'([^']+)'", output, re.S
                    )
                    if m:
                        return m.group(1).strip()
                except Exception:
                    pass

                return None

        case_index: int | None = _parse_case_to_index(case) if case else None
        if case and case_index is None:
            print(f"é”™è¯¯: æ— æ³•è§£æ case å‚æ•°: {case}")
            return False

        # å…ˆæŒ‰ case è¿‡æ»¤ï¼ˆè‹¥æœ‰ï¼‰ï¼Œå†æŒ‰æ­£ç¡®ç‡é˜ˆå€¼è¿‡æ»¤
        filtered_cases = []
        for _, row in df.iterrows():
            if case_index is not None:
                # å¦‚æœæŒ‡å®šäº†å…·ä½“çš„caseï¼Œåªå¤„ç†è¯¥caseï¼ˆä¸ç®¡æ­£ç¡®ç‡ï¼‰
                if int(row.get("é¢˜ç›®ç¼–å·", -1)) == case_index:
                    accuracy_str = row["æ•´ä½“æ­£ç¡®ç‡"]
                    accuracy = (
                        float(accuracy_str.rstrip("%")) if accuracy_str != "N/A" else 0
                    )
                    filtered_cases.append(
                        {
                            "case_num": str(row["é¢˜ç›®ç¼–å·"]).zfill(3),
                            "accuracy": accuracy,
                            "topic": row.get("é¢˜ç›®ç±»å‹", ""),
                            "query": row.get("é¢˜ç›®å†…å®¹", ""),
                        }
                    )
            else:
                # æ²¡æœ‰æŒ‡å®šcaseæ—¶ï¼ŒæŒ‰æ­£ç¡®ç‡é˜ˆå€¼è¿‡æ»¤
                accuracy_str = row["æ•´ä½“æ­£ç¡®ç‡"]
                if accuracy_str != "N/A":
                    accuracy = float(accuracy_str.rstrip("%"))
                    if accuracy <= max_accuracy:
                        filtered_cases.append(
                            {
                                "case_num": str(row["é¢˜ç›®ç¼–å·"]).zfill(3),
                                "accuracy": accuracy,
                                "topic": row.get("é¢˜ç›®ç±»å‹", ""),
                                "query": row.get("é¢˜ç›®å†…å®¹", ""),
                            }
                        )

        if not filtered_cases:
            if case_index is not None:
                print(
                    f"âŒ æœªæ‰¾åˆ° Case {str(case_index).zfill(3)}ï¼Œè¯·æ£€æŸ¥caseç¼–å·æ˜¯å¦æ­£ç¡®"
                )
            else:
                print(f"âœ… æ²¡æœ‰æ­£ç¡®ç‡ä½äº{max_accuracy}%çš„cases")
            return True

        if case_index is not None:
            print(f"ğŸ“Š å‡†å¤‡åˆ†æ Case {filtered_cases[0]['case_num']}:")
            print(f"  - æ­£ç¡®ç‡: {filtered_cases[0]['accuracy']:.1f}%")
            print(f"  - é¢˜ç›®: {filtered_cases[0]['query'][:100]}...")
        else:
            print(f"ğŸ“Š æ‰¾åˆ° {len(filtered_cases)} ä¸ªæ­£ç¡®ç‡ä½äº{max_accuracy}%çš„cases:")
            for case in filtered_cases[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(
                    f"  - Case {case['case_num']}: {case['accuracy']:.1f}% - {case['query'][:50]}..."
                )
            if len(filtered_cases) > 10:
                print(f"  ... è¿˜æœ‰ {len(filtered_cases) - 10} ä¸ªcases")

        print("=" * 60)

        # è·å–æ‰€æœ‰runs
        run_dirs = sorted(
            [
                d
                for d in self.experiment_path.iterdir()
                if d.is_dir() and d.name.startswith("run_")
            ]
        )
        if not run_dirs:
            print("é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•runç›®å½•")
            return False

        print(f"å°†å¯¹ {len(run_dirs)} ä¸ªrunsä¸­çš„ {len(filtered_cases)} ä¸ªcasesè¿›è¡Œåˆ†æ")
        print("=" * 60)

        # å¯¹æ¯ä¸ªcaseåœ¨æ‰€æœ‰runä¸­è¿›è¡Œåˆ†æ
        total_analyses = len(filtered_cases) * len(run_dirs)
        analysis_count = 0
        success_count = 0

        for case_info in filtered_cases:
            case_num = case_info["case_num"]
            print(f"\nğŸ“‹ åˆ†æ Case {case_num} (æ­£ç¡®ç‡: {case_info['accuracy']:.1f}%)")
            print(f"é¢˜ç›®: {case_info['query'][:100]}...")
            print("-" * 40)

            for run_dir in run_dirs:
                run_name = run_dir.name
                analysis_count += 1
                print(
                    f"[{analysis_count}/{total_analyses}] {run_name} - Case {case_num}...",
                    end=" ",
                )

                # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
                existing_result = None
                # æ— è®ºæ˜¯å¦æä¾›ä¸šåŠ¡çŸ¥è¯†ï¼Œåªè¦å·²æœ‰åˆ†ææŠ¥å‘Šåˆ™è·³è¿‡ï¼›
                # å¦‚éœ€å¼ºåˆ¶é‡æ–°åˆ†æï¼Œè¯·åˆ é™¤å¯¹åº”çš„åˆ†ææŠ¥å‘Šæ–‡ä»¶ã€‚
                existing_result = self.execution_analyzer.load_analysis_result(
                    run_name, case_num
                )

                if existing_result:
                    print("âœ“ (å·²ç¼“å­˜)")
                    success_count += 1
                    continue

                # æ‰§è¡Œæ–°çš„åˆ†æ
                try:
                    analysis_result = self.execution_analyzer.analyze_execution(
                        run_name,
                        case_num,
                        save_to_file=True,
                        knowledge_path=knowledge_path,
                    )
                    if analysis_result:
                        print("âœ“")
                        success_count += 1
                    else:
                        print("âœ—")
                except Exception as e:
                    print(f"âœ— (é”™è¯¯: {e})")

        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š è·¨runåˆ†æå®Œæˆ")
        print("=" * 60)
        print(f"æ€»è®¡: {total_analyses} ä¸ªåˆ†æä»»åŠ¡")
        print(f"æˆåŠŸ: {success_count} ä¸ª")
        print(f"å¤±è´¥: {total_analyses - success_count} ä¸ª")
        print(f"æˆåŠŸç‡: {success_count/total_analyses*100:.1f}%")

        # å¦‚æœå¯ç”¨äº†summaryåŠŸèƒ½ï¼Œè¿›è¡Œè·¨runæ±‡æ€»åˆ†æ
        if enable_summary and success_count > 0:
            print("\n" + "=" * 60)
            print("ğŸ“‹ å¼€å§‹è·¨runæ±‡æ€»åˆ†æ...")
            print("=" * 60)

            summary_success = self._run_cross_run_summary(
                filtered_cases, run_dirs, knowledge_path
            )
            if summary_success:
                print("âœ… è·¨runæ±‡æ€»åˆ†æå®Œæˆ")
            else:
                print("âŒ è·¨runæ±‡æ€»åˆ†æå¤±è´¥")
                return False

        return True

    def run_batch_execution_analysis(
        self, run_name, failed_only=True, knowledge_path=None
    ):
        """
        æ‰¹é‡è¿è¡Œæ™ºèƒ½ä½“æ‰§è¡Œåˆ†æ

        Args:
            run_name: runåç§°
            failed_only: æ˜¯å¦ä»…åˆ†æå¤±è´¥çš„casesï¼ˆé»˜è®¤Trueï¼‰
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ” å¯åŠ¨æ‰¹é‡æ‰§è¡Œåˆ†ææ¨¡å¼ - Run: {run_name}")
        if knowledge_path:
            print(f"ğŸ“š ä½¿ç”¨ä¸šåŠ¡çŸ¥è¯†: {knowledge_path}")

        # è·å–è¦åˆ†æçš„cases
        cases_to_analyze = self._get_cases_to_analyze(run_name, failed_only)

        if not cases_to_analyze:
            if failed_only:
                print("âœ… æ²¡æœ‰å¤±è´¥çš„caseséœ€è¦åˆ†æ")
            else:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•cases")
            return True

        print(
            f"ğŸ“Š å°†åˆ†æ {len(cases_to_analyze)} ä¸ªcases: {', '.join(cases_to_analyze)}"
        )
        print("=" * 60)

        # ä¾æ¬¡åˆ†ææ¯ä¸ªcase
        results = []
        for i, case_num in enumerate(cases_to_analyze, 1):
            print(f"\n[{i}/{len(cases_to_analyze)}] åˆ†æ Case {case_num}...")
            print("-" * 40)

            # æ— è®ºæ˜¯å¦æä¾›ä¸šåŠ¡çŸ¥è¯†ï¼Œåªè¦å·²æœ‰åˆ†ææŠ¥å‘Šåˆ™è·³è¿‡ï¼›
            # å¦‚éœ€å¼ºåˆ¶é‡æ–°åˆ†æï¼Œè¯·åˆ é™¤å¯¹åº”çš„åˆ†ææŠ¥å‘Šæ–‡ä»¶ã€‚
            existing_result = self.execution_analyzer.load_analysis_result(
                run_name, case_num
            )

            if existing_result:
                print("âœ… æ‰¾åˆ°å·²æœ‰çš„åˆ†æç»“æœï¼Œè·³è¿‡é‡æ–°åˆ†æï¼ˆåˆ é™¤åˆ†ææŠ¥å‘Šå¯é‡æ–°ç”Ÿæˆï¼‰")
                results.append((case_num, "CACHED", existing_result))
                continue

            # æ‰§è¡Œæ–°çš„åˆ†æ
            analysis_result = self.execution_analyzer.analyze_execution(
                run_name, case_num, save_to_file=True, knowledge_path=knowledge_path
            )
            if analysis_result:
                print("\nğŸ“‹ åˆ†æç»“æœ:")
                print("===ANALYSIS_START===")
                print(analysis_result)
                print("===ANALYSIS_END===")
                results.append((case_num, "SUCCESS", analysis_result))
            else:
                print("âŒ åˆ†æå¤±è´¥")
                results.append((case_num, "FAILED", None))

        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆ")
        print("=" * 60)
        success_count = sum(1 for _, status, _ in results if status == "SUCCESS")
        cached_count = sum(1 for _, status, _ in results if status == "CACHED")
        failed_count = sum(1 for _, status, _ in results if status == "FAILED")
        print(f"æ€»è®¡: {len(results)} ä¸ªcases")
        print(f"æ–°åˆ†æ: {success_count} ä¸ª")
        print(f"å·²ç¼“å­˜: {cached_count} ä¸ª")
        print(f"å¤±è´¥: {failed_count} ä¸ª")

        return success_count > 0

    def _get_cases_to_analyze(self, run_name, failed_only=True):
        """
        è·å–è¦åˆ†æçš„casesåˆ—è¡¨

        Args:
            run_name: runåç§°
            failed_only: æ˜¯å¦ä»…è·å–å¤±è´¥çš„cases

        Returns:
            caseç¼–å·åˆ—è¡¨
        """
        # åŠ è½½å®éªŒæ•°æ®
        if not self.data_loader.load_experiment_data():
            print("é”™è¯¯: æ— æ³•åŠ è½½å®éªŒæ•°æ®")
            return []

        # å°è¯•ä¸åŒçš„runç›®å½•å‘½åæ ¼å¼
        run_dir = None
        possible_names = [
            run_name,  # åŸå§‹åç§°
            run_name.replace("run", "run_"),  # run001 -> run_001
            f"run_{run_name.replace('run', '').zfill(3)}",  # run1 -> run_001
            f"run_{run_name.replace('run_', '').zfill(3)}",  # run_1 -> run_001
        ]

        for name in possible_names:
            test_dir = self.experiment_path / name
            if test_dir.exists():
                run_dir = test_dir
                break

        if not run_dir:
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°runç›®å½•: {run_name}")
            print(f"å·²å°è¯•: {', '.join(possible_names)}")
            return []

        # å°è¯•ä¸åŒçš„ç»“æœæ–‡ä»¶å
        result_file = None
        possible_files = [
            run_dir / "result.yaml",
            run_dir / "run_summary.yaml",
            run_dir / "results.yaml",
        ]

        for file in possible_files:
            if file.exists():
                result_file = file
                break

        if not result_file:
            print(f"é”™è¯¯: åœ¨ {run_dir} ä¸­æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶")
            print(f"å·²å°è¯•: result.yaml, run_summary.yaml, results.yaml")
            return []

        try:
            import yaml

            with open(result_file, "r", encoding="utf-8") as f:
                results = yaml.safe_load(f)

            cases_to_analyze = []

            # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†æ•°æ®
            if result_file.name == "run_summary.yaml":
                # run_summary.yaml æ ¼å¼ - cases å¯èƒ½åœ¨ benchmarks å­—æ®µä¸‹
                cases_data = results.get("benchmarks", results.get("cases", []))
            else:
                # result.yaml æ ¼å¼
                cases_data = results if isinstance(results, list) else []

            # éå†æ‰€æœ‰cases
            for idx, case_result in enumerate(cases_data):
                # è·å–caseç¼–å·
                case_id = (
                    case_result.get("test_id")
                    or case_result.get("case_id")
                    or case_result.get("id")
                )
                if case_id is None:
                    # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„IDï¼Œä½¿ç”¨ç´¢å¼•+1ä½œä¸ºcaseç¼–å·
                    case_id = idx + 1
                case_num = str(case_id).lstrip("test_").lstrip("case_").zfill(3)

                # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
                is_correct = case_result.get("is_correct", False) or case_result.get(
                    "correct", False
                )

                # æ ¹æ®æ¡ä»¶å†³å®šæ˜¯å¦æ·»åŠ åˆ°åˆ†æåˆ—è¡¨
                if failed_only:
                    if not is_correct:
                        cases_to_analyze.append(case_num)
                else:
                    cases_to_analyze.append(case_num)

            return sorted(cases_to_analyze)

        except Exception as e:
            print(f"é”™è¯¯: è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _run_cross_run_summary(self, filtered_cases, run_dirs, knowledge_path=None):
        """
        æ‰§è¡Œè·¨runçš„æ±‡æ€»åˆ†æ

        Args:
            filtered_cases: ç­›é€‰å‡ºçš„caseåˆ—è¡¨
            run_dirs: runç›®å½•åˆ—è¡¨
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ”¶é›†æ‰€æœ‰åˆ†æå†…å®¹
            all_analysis_content = []

            print("ğŸ” æ”¶é›†åˆ†æå†…å®¹...")
            for case_info in filtered_cases:
                case_num = case_info["case_num"]
                print(f"ğŸ“‹ æ”¶é›† Case {case_num} çš„åˆ†æå†…å®¹...")

                case_analysis_content = []
                for run_dir in run_dirs:
                    run_name = run_dir.name
                    analysis_file = run_dir / "analysis" / f"case_{case_num}.txt"

                    if analysis_file.exists():
                        try:
                            with open(analysis_file, "r", encoding="utf-8") as f:
                                file_content = f.read()

                            # æå–åˆ†æå†…å®¹
                            extracted_content = (
                                self._extract_analysis_content_from_file(
                                    file_content, f"{run_name}_case_{case_num}.txt"
                                )
                            )
                            if extracted_content:
                                case_analysis_content.append(extracted_content)

                        except Exception as e:
                            print(f"  âš ï¸ è¯»å– {run_name}/case_{case_num}.txt å¤±è´¥: {e}")
                            continue

                if case_analysis_content:
                    # åˆå¹¶è¯¥caseçš„æ‰€æœ‰runåˆ†æ
                    case_combined = f"\n\n=== Case {case_num} è·¨Runåˆ†ææ±‡æ€» ===\n"
                    case_combined += f"é¢˜ç›®: {case_info['query'][:100]}...\n"
                    case_combined += f"æ­£ç¡®ç‡: {case_info['accuracy']:.1f}%\n"
                    case_combined += "=" * 50 + "\n\n"
                    case_combined += "\n\n".join(case_analysis_content)

                    all_analysis_content.append(case_combined)
                    print(f"  âœ… æ”¶é›†åˆ° {len(case_analysis_content)} ä¸ªrunçš„åˆ†æå†…å®¹")
                else:
                    print(f"  âš ï¸ Case {case_num} æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æå†…å®¹")

            if not all_analysis_content:
                print("âŒ æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•åˆ†æå†…å®¹")
                return False

            print(f"âœ… æ€»å…±æ”¶é›†åˆ° {len(all_analysis_content)} ä¸ªcaseçš„åˆ†æå†…å®¹")

            # åˆå¹¶æ‰€æœ‰åˆ†æå†…å®¹
            combined_content = "\n\n" + "=" * 80 + "\n\n".join(all_analysis_content)

            # è°ƒç”¨summaryåˆ†æ
            print("ğŸ”§ å¼€å§‹æ±‡æ€»åˆ†æ...")
            summary_result = self._call_summary_analysis(
                combined_content, knowledge_path
            )

            if summary_result:
                # ä¿å­˜æ±‡æ€»ç»“æœåˆ°å®éªŒç›®å½•ä¸‹çš„analysisæ–‡ä»¶å¤¹
                analysis_dir = self.experiment_path / "analysis"
                analysis_dir.mkdir(exist_ok=True, parents=True)

                from datetime import datetime

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                # ç”Ÿæˆcaseåˆ—è¡¨å­—ç¬¦ä¸²ï¼Œé™åˆ¶é•¿åº¦é¿å…æ–‡ä»¶åè¿‡é•¿
                case_nums = [str(case_info["case_num"]) for case_info in filtered_cases]
                case_str = "_".join(case_nums[:10])  # æœ€å¤šå–å‰10ä¸ªcaseï¼Œé¿å…æ–‡ä»¶åè¿‡é•¿
                if len(filtered_cases) > 10:
                    case_str += f"_and_{len(filtered_cases)-10}_more"
                summary_file = (
                    analysis_dir / f"cross_run_summary_cases_{case_str}_{timestamp}.txt"
                )

                with open(summary_file, "w", encoding="utf-8") as f:
                    f.write("=" * 80 + "\n")
                    f.write("è·¨Runæ±‡æ€»åˆ†ææŠ¥å‘Š\n")
                    f.write(
                        f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    )
                    f.write(f"åˆ†æçš„Cases: {len(filtered_cases)} ä¸ª\n")
                    f.write(f"æ¶‰åŠçš„Runs: {len(run_dirs)} ä¸ª\n")
                    f.write("=" * 80 + "\n\n")
                    f.write(summary_result)
                    f.write("\n\n")

                print(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
                return True
            else:
                print("âŒ æ±‡æ€»åˆ†æå¤±è´¥")
                return False

        except Exception as e:
            print(f"é”™è¯¯: è·¨runæ±‡æ€»åˆ†æå¤±è´¥: {e}")
            return False

    def _extract_analysis_content_from_file(self, file_content, file_name):
        """
        ä»åˆ†ææ–‡ä»¶ä¸­æå–å†…å®¹

        Args:
            file_content: æ–‡ä»¶å†…å®¹
            file_name: æ–‡ä»¶åï¼ˆç”¨äºæ ‡è¯†ï¼‰

        Returns:
            æå–çš„åˆ†æå†…å®¹
        """
        try:
            start_marker = "===ANALYSIS_START==="
            end_marker = "===ANALYSIS_END==="

            start_pos = file_content.find(start_marker)
            if start_pos == -1:
                return None

            end_pos = file_content.find(end_marker, start_pos)
            if end_pos == -1:
                return None

            # æå–æ ‡è®°ä¹‹é—´çš„å†…å®¹
            content_start = start_pos + len(start_marker)
            extracted_content = file_content[content_start:end_pos].strip()

            if not extracted_content:
                return None

            # æ·»åŠ æ–‡ä»¶æ ‡è¯†
            formatted_content = f"--- æ¥è‡ª: {file_name} ---\n{extracted_content}"
            return formatted_content

        except Exception as e:
            print(f"é”™è¯¯: ä» {file_name} æå–åˆ†æå†…å®¹æ—¶å‡ºé”™: {e}")
            return None

    def _call_summary_analysis(self, analysis_content, knowledge_path=None):
        """
        è°ƒç”¨summaryåˆ†æåŠŸèƒ½

        Args:
            analysis_content: åˆ†æå†…å®¹
            knowledge_path: ä¸šåŠ¡çŸ¥è¯†è·¯å¾„

        Returns:
            æ±‡æ€»åˆ†æç»“æœ
        """
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ç”¨äºåˆ†æ
            import tempfile
            import subprocess
            from datetime import datetime

            # åˆ›å»ºä¸´æ—¶çš„ summary_analyzer æ¥åŠ è½½çŸ¥è¯†å’Œæå–ç»“æœ
            from summary_analyzer import SummaryAnalyzer

            temp_summary_analyzer = SummaryAnalyzer(self.data_loader)

            # åŠ è½½ä¸šåŠ¡çŸ¥è¯†
            knowledge_content = ""
            if knowledge_path:
                knowledge_content = temp_summary_analyzer._load_knowledge(
                    knowledge_path
                )
                if knowledge_content:
                    print(f"âœ… æˆåŠŸåŠ è½½ä¸šåŠ¡çŸ¥è¯† ({len(knowledge_content)} å­—ç¬¦)")

            # æ„å»ºdolphinå‘½ä»¤
            cmd_parts = [
                str(self.data_loader.dolphin_cmd),
                "--folder",
                str(Path(__file__).parent / "dolphins"),
                "--agent",
                "summary",
                "--analysis_content",
                analysis_content,
                "--busi_knowledge",
                knowledge_content,
                "--output-variables",
                "suggestions",
            ]

            # æ‰§è¡Œåˆ†æå‘½ä»¤
            result = subprocess.run(
                cmd_parts,
                capture_output=True,
                text=True,
                timeout=500,
                cwd=str(self.data_loader.root_dir),
            )

            if result.returncode == 0:
                # æå–åˆ†æç»“æœ
                extracted = temp_summary_analyzer._extract_summary_result(result.stdout)
                if extracted:
                    return extracted
                else:
                    print("è­¦å‘Š: æ— æ³•ä»è¾“å‡ºä¸­æå–æ±‡æ€»ç»“æœ")
                    return "æ±‡æ€»åˆ†æå®Œæˆï¼Œä½†æ— æ³•æå–åˆ†æç»“æœã€‚"
            else:
                print(f"é”™è¯¯: æ±‡æ€»åˆ†æå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
                if result.stderr:
                    print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return None

        except Exception as e:
            print(f"é”™è¯¯: è°ƒç”¨æ±‡æ€»åˆ†ææ—¶å‡ºé”™: {e}")
            return None

    def run_simulation_inject(
        self,
        case_id,
        entrypoint=None,
        inject_var="injects",
        knowledge_path=None,
        max_iterations=5,
        timeout_seconds=500,
    ):
        """å…¥å£ï¼šå§”æ‰˜ SimulationInjector æ‰§è¡Œå…·ä½“é€»è¾‘"""
        injector = SimulationInjector(
            experiment_path=self.experiment_path,
            data_loader=self.data_loader,
            cross_run_analysis_callback=self.run_cross_run_analysis,
        )
        return injector.run_simulation_inject(
            case_id=case_id,
            entrypoint=entrypoint,
            inject_var=inject_var,
            knowledge_path=knowledge_path,
            max_iterations=max_iterations,
            timeout_seconds=timeout_seconds,
        )

    def run_batch_simulation_inject(
        self,
        accuracy_threshold=10.0,
        entrypoint=None,
        inject_var="injects",
        knowledge_path=None,
        max_iterations=5,
        timeout_seconds=500,
    ):
        """å…¥å£ï¼šå§”æ‰˜ SimulationInjector æ‰§è¡Œå…·ä½“é€»è¾‘ï¼ˆæ‰¹é‡ï¼‰"""
        injector = SimulationInjector(
            experiment_path=self.experiment_path,
            data_loader=self.data_loader,
            cross_run_analysis_callback=self.run_cross_run_analysis,
        )
        return injector.run_batch_simulation_inject(
            accuracy_threshold=accuracy_threshold,
            entrypoint=entrypoint,
            inject_var=inject_var,
            knowledge_path=knowledge_path,
            max_iterations=max_iterations,
            timeout_seconds=timeout_seconds,
        )

    # æ³¨ï¼šsimulation-inject ç›¸å…³å®ç°å·²è¿ç§»è‡³ SimulationInjector
