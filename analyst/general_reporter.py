#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€»ä½“æŠ¥å‘Šç”Ÿæˆå™¨

è´Ÿè´£ç”Ÿæˆå®éªŒçš„æ€»ä½“åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
- é…ç½®å¯¹æ¯”åˆ†æ
- å‡†ç¡®ç‡ç»Ÿè®¡
- å»¶è¿Ÿæ€§èƒ½åˆ†æ
- Tokenæ¶ˆè€—åˆ†æ
- è°ƒç”¨é“¾åˆ†æ
- æ·±åº¦åˆ†æï¼ˆä½¿ç”¨general.dphï¼‰
"""

import os
import pandas as pd
import yaml
import json
import subprocess
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import defaultdict

from dolphin.core.common.constants import (
    DOLPHIN_VARIABLES_OUTPUT_START,
    DOLPHIN_VARIABLES_OUTPUT_END,
)

try:
    from .base_analyzer import BaseAnalyzer
except ImportError:
    from base_analyzer import BaseAnalyzer


class GeneralReporter(BaseAnalyzer):
    """æ€»ä½“æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, data_loader):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            data_loader: ExperimentDataLoaderå®ä¾‹ï¼Œç”¨äºåŠ è½½å®éªŒæ•°æ®
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(data_loader)

    def generate_report(self):
        """ç”Ÿæˆæ€»ä½“åˆ†ææŠ¥å‘Š"""
        print("ğŸ” å¼€å§‹ç”Ÿæˆæ€»ä½“åˆ†ææŠ¥å‘Š...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_name = f"{self.experiment_name}_general_report_{timestamp}"

        # åˆ†ææ•°æ®
        config_df = self.data_loader.analyze_configs()
        accuracy_df = self.data_loader.analyze_accuracy()
        factor_groups = self.data_loader.analyze_by_factors()
        individual_variables = self.data_loader.analyze_individual_variables()
        run_labels = self.data_loader.generate_run_labels()
        results_df = self.data_loader.create_detailed_comparison()
        consecutive_patterns = self.data_loader.detect_consecutive_errors(results_df)
        latency_df = self.data_loader.analyze_latency()
        token_df = self.data_loader.analyze_token_consumption()
        impact_df = self.data_loader.analyze_config_impact(config_df, accuracy_df)
        call_chain_summary = self.data_loader.analyze_all_call_chains()

        # ç”Ÿæˆæ·±åº¦åˆ†æ
        print("ğŸ“Š æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ...")
        deep_analysis = self._generate_deep_analysis(
            config_df,
            accuracy_df,
            latency_df,
            token_df,
            factor_groups,
            call_chain_summary,
        )

        # æ—¥å¿—åˆ†æ
        log_analyses = {}
        for run in self.data_loader.runs:
            run_dir = self.experiment_path / run["run_id"]
            log_analyses[run["run_id"]] = self.data_loader.analyze_case_logs(run_dir)

        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report_path = self._write_report(
            report_name,
            config_df,
            accuracy_df,
            latency_df,
            token_df,
            factor_groups,
            impact_df,
            run_labels,
            results_df,
            consecutive_patterns,
            call_chain_summary,
            deep_analysis,
            log_analyses,
            individual_variables,
        )

        # ç”ŸæˆCSVè¯¦ç»†æ•°æ®
        csv_path = self.reports_dir / f"{report_name}.csv"
        results_df.to_csv(csv_path, index=False, encoding="utf-8")

        print("âœ… æ€»ä½“åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“Š æŸ¥çœ‹æŠ¥å‘Š: {report_path}")
        print(f"ğŸ“ˆ è¯¦ç»†æ•°æ®: {csv_path}")

        return report_path, csv_path

    def _generate_deep_analysis(
        self,
        config_df,
        accuracy_df,
        latency_df,
        token_df,
        factor_groups,
        call_chain_summary,
    ):
        """ç”Ÿæˆæ·±åº¦åˆ†æå†…å®¹"""
        # å‡†å¤‡å®éªŒæ•°æ®ç»“æ„
        experiments = []
        for _, config_row in config_df.iterrows():
            run_id = config_row["Run ID"]

            # æŸ¥æ‰¾å¯¹åº”çš„å‡†ç¡®ç‡ã€å»¶è¿Ÿã€tokenæ•°æ®
            acc_row = (
                accuracy_df[accuracy_df["Run ID"] == run_id].iloc[0]
                if not accuracy_df[accuracy_df["Run ID"] == run_id].empty
                else None
            )
            lat_row = (
                latency_df[latency_df["Run ID"] == run_id].iloc[0]
                if not latency_df[latency_df["Run ID"] == run_id].empty
                else None
            )
            tok_row = (
                token_df[token_df["Run ID"] == run_id].iloc[0]
                if not token_df[token_df["Run ID"] == run_id].empty
                else None
            )

            exp_data = {
                "run_name": run_id,
                "Model Name": config_row.get("Model Name", ""),
                "Encoded Variables": config_row.get("Variables", ""),
                "Accuracy": (
                    float(acc_row["Accuracy"].rstrip("%")) / 100
                    if acc_row is not None
                    else 0
                ),
                "Latency P50 (seconds)": (
                    lat_row.get("P50 Latency", 0) if lat_row is not None else 0
                ),
                "Total Tokens": (
                    tok_row.get("Total All Tokens", 0) if tok_row is not None else 0
                ),
                "Tool Calls": (
                    tok_row.get("Total Tool Calls", 0) if tok_row is not None else 0
                ),
                "Interactions": 0,  # Will be filled after checking call_chain_summary structure
            }
            experiments.append(exp_data)

        # Fill in interactions from call_chain_summary if available
        if call_chain_summary and isinstance(call_chain_summary, dict):
            run_summaries = call_chain_summary.get("run_summaries", [])
            if isinstance(run_summaries, list):
                for exp_data in experiments:
                    run_id = exp_data["run_name"]
                    # Find the matching run in run_summaries
                    for run_summary in run_summaries:
                        if run_summary.get("run_id") == run_id:
                            exp_data["Interactions"] = run_summary.get(
                                "avg_interaction_rounds", 0
                            )
                            break

        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡ - ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ•°å€¼ç±»å‹
        def to_numeric(val):
            """Convert value to numeric, handling strings and None"""
            if val is None:
                return 0
            if isinstance(val, str):
                # Remove commas and extract numeric part from string
                import re

                clean_val = val.replace(",", "")
                match = re.search(r"[\d.]+", clean_val)
                if match:
                    return float(match.group())
                return 0
            return float(val)

        accuracies = [e["Accuracy"] for e in experiments]
        latencies = [to_numeric(e["Latency P50 (seconds)"]) for e in experiments]
        tokens = [to_numeric(e["Total Tokens"]) for e in experiments]
        tool_calls = [to_numeric(e["Tool Calls"]) for e in experiments]
        interactions = [to_numeric(e["Interactions"]) for e in experiments]

        summary = {
            "accuracy_mean": np.mean(accuracies) if accuracies else 0,
            "accuracy_std": np.std(accuracies) if accuracies else 0,
            "latency_p50": np.median(latencies) if latencies else 0,
            "latency_p99": (
                np.percentile(latencies, 99)
                if latencies and len(latencies) > 1
                else max(latencies) if latencies else 0
            ),
            "total_tokens_mean": np.mean(tokens) if tokens else 0,
            "tool_calls_mean": np.mean(tool_calls) if tool_calls else 0,
            "interactions_mean": np.mean(interactions) if interactions else 0,
        }

        return self._call_general_agent(experiments, summary)

    def _call_general_agent(self, experiments, summary):
        """è°ƒç”¨general.dphè¿›è¡Œæ·±åº¦åˆ†æ"""
        try:
            # å‡†å¤‡åˆ†ææ•°æ®
            data_summary = {
                "total_experiments": len(experiments),
                "summary_metrics": summary,
                "experiments": experiments,
            }

            # æ„å»ºdolphinå‘½ä»¤
            cmd_parts = [
                str(self.dolphin_cmd),
                "--folder",
                str(self.root_dir / "experiments" / "analyst" / "dolphins"),
                "--agent",
                "general",
                "--data",
                json.dumps(data_summary, ensure_ascii=False),
                "--query",
                "è¯·åˆ†æè¿™ä¸ªå®éªŒçš„ç»“æœï¼Œé‡ç‚¹åˆ†æï¼š1)ä¸åŒæ¨¡å‹çš„æ€§èƒ½å·®å¼‚å’ŒåŸå› ï¼›2)ä¸åŒé…ç½®(variables)å¯¹ç»“æœçš„å½±å“ï¼›3)å»¶è¿Ÿæ€§èƒ½åˆ†æï¼›4)Tokenæ¶ˆè€—æ•ˆç‡åˆ†æï¼›5)è°ƒç”¨é“¾å’Œå·¥å…·ä½¿ç”¨æ¨¡å¼åˆ†æï¼›6)äº¤äº’è½®æ•°ä¸æˆåŠŸç‡çš„å…³ç³»ï¼›7)Tokenæ¶ˆè€—ä¸å‡†ç¡®ç‡çš„æ€§ä»·æ¯”åˆ†æï¼›8)ç»™å‡ºå®ç”¨çš„æ”¹è¿›å»ºè®®ã€‚è¯·æä¾›ä¸“ä¸šçš„åˆ†æå’Œæ´å¯Ÿã€‚",
                "--output-variables",
                "analysis_result",
            ]

            # è¿è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd_parts,
                capture_output=True,
                text=True,
                timeout=500,
                cwd=str(self.root_dir),
            )

            if result.returncode == 0:
                # è§£æè¾“å‡º
                output = result.stdout

                # æ–¹æ³•1: æŸ¥æ‰¾DOLPHIN_VARIABLES_OUTPUTæ ‡è®°
                start_marker = DOLPHIN_VARIABLES_OUTPUT_START
                end_marker = DOLPHIN_VARIABLES_OUTPUT_END

                if start_marker in output and end_marker in output:
                    start_idx = output.index(start_marker) + len(start_marker)
                    end_idx = output.index(end_marker)
                    json_str = output[start_idx:end_idx].strip()

                    try:
                        variables = json.loads(json_str)
                        if "analysis_result" in variables:
                            result_data = variables["analysis_result"]
                            if (
                                isinstance(result_data, dict)
                                and "answer" in result_data
                            ):
                                return result_data["answer"]
                            elif isinstance(result_data, str):
                                return result_data
                    except json.JSONDecodeError:
                        pass

                # æ–¹æ³•2: æŸ¥æ‰¾"Agent general:"å¼€å§‹çš„åœ°æ–¹
                output_lines = output.split("\n")
                start_idx = -1
                for i, line in enumerate(output_lines):
                    if "Agent general:" in line:
                        start_idx = i + 1
                        break

                if start_idx > 0:
                    analysis_lines = output_lines[start_idx:]
                    if analysis_lines:
                        return "\n".join(analysis_lines)

                return "æ·±åº¦åˆ†æå®Œæˆï¼Œä½†æ— æ³•æå–åˆ†æç»“æœã€‚"
            else:
                print(f"Warning: General agent failed: {result.stderr}")
                return "æ·±åº¦åˆ†æè°ƒç”¨å¤±è´¥ã€‚"
        except Exception as e:
            print(f"Warning: Failed to call general agent: {e}")
            return "æ·±åº¦åˆ†ææ‰§è¡Œå¼‚å¸¸ã€‚"

    def _write_report(
        self,
        report_name,
        config_df,
        accuracy_df,
        latency_df,
        token_df,
        factor_groups,
        impact_df,
        run_labels,
        results_df,
        consecutive_patterns,
        call_chain_summary,
        deep_analysis,
        log_analyses,
        individual_variables,
    ):
        """å†™å…¥æŠ¥å‘Šæ–‡ä»¶"""
        report_path = self.reports_dir / f"{report_name}.txt"

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(f"å®éªŒæ€»ä½“åˆ†ææŠ¥å‘Š\n")
            f.write(f"{'='*60}\n")
            f.write(f"å®éªŒåç§°: {self.experiment_name}\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å®éªŒè·¯å¾„: {self.experiment_path}\n\n")

            # 1. å®éªŒé…ç½®å¯¹æ¯”
            f.write("1. å®éªŒé…ç½®å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            f.write(config_df.to_string(index=False))
            f.write("\n\n")

            # 1.0 Runæ ‡è¯†ç¬¦è¯´æ˜
            f.write("1.0 Runæ ‡è¯†ç¬¦è¯´æ˜\n")
            f.write("-" * 30 + "\n")
            f.write("Run IDåçš„[xxxx]æ ‡è¯†ç¬¦å«ä¹‰ï¼š\n")

            # ä½¿ç”¨æ•°æ®åŠ è½½å™¨çš„å›¾ä¾‹ä¿¡æ¯
            if (
                hasattr(self.data_loader, "run_label_legend")
                and self.data_loader.run_label_legend
            ):
                for code, meaning in sorted(self.data_loader.run_label_legend.items()):
                    f.write(f"  {code} = {meaning}\n")
            else:
                # å¦‚æœæ²¡æœ‰å›¾ä¾‹ä¿¡æ¯ï¼Œä»å®é™…æ•°æ®ä¸­æ¨æ–­
                unique_codes = set()
                for run_id, label in run_labels.items():
                    if "[" in label and "]" in label:
                        identifier = label.split("[")[1].split("]")[0]
                        for char in identifier:
                            if char.isupper():
                                unique_codes.add(char)

                # æ ¹æ®é…ç½®ä¿¡æ¯æ¨æ–­æ ‡è¯†ç¬¦å«ä¹‰
                config_df = self.data_loader.analyze_configs()
                if "Model Name" in config_df.columns:
                    model_names = config_df["Model Name"].unique()
                    for code in sorted(unique_codes):
                        # æ ¹æ®å®é™…ä½¿ç”¨çš„æ¨¡å‹æ¥æ˜ å°„æ ‡è¯†ç¬¦
                        found_meaning = False
                        for model in model_names:
                            if "deepseek" in model.lower() and code == "D":
                                f.write(f"  D = DeepSeekæ¨¡å‹\n")
                                found_meaning = True
                                break
                            elif "qwen" in model.lower() and code == "Q":
                                f.write(f"  Q = Qwenæ¨¡å‹\n")
                                found_meaning = True
                                break
                            elif "gpt" in model.lower() and code == "G":
                                f.write(f"  G = GPTæ¨¡å‹\n")
                                found_meaning = True
                                break
                            elif "kimi" in model.lower() and (
                                code == "K" or code == "A" or code == "B"
                            ):
                                f.write(f"  {code} = Kimiæ¨¡å‹\n")
                                found_meaning = True
                                break

                        if not found_meaning:
                            f.write(f"  {code} = æœªçŸ¥é…ç½®é¡¹\n")
            f.write("\n")

            # 1.1 é…ç½®å› å­å¯¹å‡†ç¡®ç‡çš„å½±å“åˆ†æ
            f.write("1.1 é…ç½®å› å­å¯¹å‡†ç¡®ç‡çš„å½±å“åˆ†æ\n")
            f.write(impact_df.to_string(index=False))
            f.write("\n")

            # 2. å‡†ç¡®ç‡å¯¹æ¯”
            f.write("2. å‡†ç¡®ç‡å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            accuracy_df_labeled = accuracy_df.copy()
            accuracy_df_labeled["Run ID"] = accuracy_df_labeled["Run ID"].apply(
                lambda x: run_labels.get(x, x)
            )
            f.write(accuracy_df_labeled.to_string(index=False))
            f.write("\n\n")

            # 3. æŒ‰é…ç½®å› å­åˆ†ç»„çš„å‡†ç¡®ç‡å¯¹æ¯”
            f.write("3. æŒ‰é…ç½®å› å­åˆ†ç»„çš„å‡†ç¡®ç‡å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")

            # è¾“å‡ºfactor_groupsçš„å†…å®¹
            for factor_name, groups in factor_groups.items():
                f.write(f"\næŒ‰ {factor_name} åˆ†ç»„:\n\n")
                for group_value, group_info in groups.items():
                    f.write(f"  {group_value}:\n")
                    for run_info in group_info:
                        run_id = run_info["run_id"]
                        accuracy = run_info["accuracy"]
                        total = run_info["total"]
                        correct = run_info["correct"]
                        avg_latency = run_info.get("avg_latency", 0)
                        tokens_per_case = run_info.get("tokens_per_case", 0)

                        run_label = run_labels.get(run_id, run_id)
                        f.write(f"    {run_label}: {accuracy:.2%} ({correct}/{total})")
                        if avg_latency > 0:
                            f.write(f" å»¶è¿Ÿ{avg_latency:.1f}s")
                        if tokens_per_case > 0:
                            f.write(f" tokens{int(tokens_per_case)}/case")
                        f.write("\n")

                    if len(group_info) > 1:
                        accuracies = [r["accuracy"] for r in group_info]
                        latencies = [r["avg_latency"] for r in group_info]
                        tokens_per_case = [
                            r.get("avg_tokens_per_case", 0) for r in group_info
                        ]
                        llm_calls = [r.get("avg_llm_calls", 0) for r in group_info]

                        avg_acc = sum(accuracies) / len(accuracies)
                        avg_lat = sum(latencies) / len(latencies)
                        avg_tok = sum(tokens_per_case) / len(tokens_per_case)
                        avg_llm = sum(llm_calls) / len(llm_calls)

                        # è®¡ç®—æ ‡å‡†å·®å’Œæ–¹å·®
                        import numpy as np

                        std_acc = np.std(accuracies) if len(accuracies) > 1 else 0
                        var_acc = np.var(accuracies) if len(accuracies) > 1 else 0
                        std_lat = np.std(latencies) if len(latencies) > 1 else 0
                        var_lat = np.var(latencies) if len(latencies) > 1 else 0
                        std_tok = (
                            np.std(tokens_per_case) if len(tokens_per_case) > 1 else 0
                        )
                        var_tok = (
                            np.var(tokens_per_case) if len(tokens_per_case) > 1 else 0
                        )

                        f.write(
                            f"    å¹³å‡å‡†ç¡®ç‡: {avg_acc:.2%} (Â±{std_acc:.2%}, æ–¹å·®:{var_acc:.6f})\n"
                        )
                        f.write(
                            f"    å¹³å‡å»¶è¿Ÿ: {avg_lat:.1f}s (Â±{std_lat:.1f}s, æ–¹å·®:{var_lat:.2f})\n"
                        )
                        f.write(
                            f"    å¹³å‡tokens/case: {int(avg_tok)} (Â±{int(std_tok)}, æ–¹å·®:{int(var_tok)})\n"
                        )
                        f.write(f"    å¹³å‡LLMè°ƒç”¨/case: {avg_llm:.1f}\n")
                    f.write("\n")
                f.write("\n")

            # æŒ‰å•ä¸ªå˜é‡åˆ†ç»„åˆ†æ
            if individual_variables:
                f.write("æŒ‰å•ä¸ªå˜é‡åˆ†ç»„åˆ†æ:\n")
                for var_name, var_groups in individual_variables.items():
                    f.write(f"\næŒ‰ {var_name} åˆ†ç»„:\n\n")
                    for value, stats in var_groups.items():
                        f.write(f"  {var_name}={value}:\n")
                        for run_info in stats:
                            run_id = run_info["run_id"]
                            accuracy = run_info["accuracy"]
                            total = run_info["total"]
                            correct = run_info["correct"]
                            avg_latency = run_info.get("avg_latency", 0)
                            tokens_per_case = run_info.get("tokens_per_case", 0)

                            run_label = run_labels.get(run_id, run_id)
                            f.write(
                                f"    {run_label}: {accuracy:.2%} ({correct}/{total})"
                            )
                            if avg_latency > 0:
                                f.write(f" å»¶è¿Ÿ{avg_latency:.1f}s")
                            if tokens_per_case > 0:
                                f.write(f" tokens{int(tokens_per_case)}/case")
                            f.write("\n")

                        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                        if len(stats) > 1:
                            accuracies = [r["accuracy"] for r in stats]
                            latencies = [r["avg_latency"] for r in stats]
                            tokens_per_case = [
                                r.get("avg_tokens_per_case", 0) for r in stats
                            ]
                            llm_calls = [r.get("avg_llm_calls", 0) for r in stats]

                            avg_acc = sum(accuracies) / len(accuracies)
                            avg_lat = sum(latencies) / len(latencies)
                            avg_tok = sum(tokens_per_case) / len(tokens_per_case)
                            avg_llm = sum(llm_calls) / len(llm_calls)

                            # è®¡ç®—æ ‡å‡†å·®å’Œæ–¹å·®
                            import numpy as np

                            std_acc = np.std(accuracies) if len(accuracies) > 1 else 0
                            var_acc = np.var(accuracies) if len(accuracies) > 1 else 0
                            std_lat = np.std(latencies) if len(latencies) > 1 else 0
                            var_lat = np.var(latencies) if len(latencies) > 1 else 0
                            std_tok = (
                                np.std(tokens_per_case)
                                if len(tokens_per_case) > 1
                                else 0
                            )
                            var_tok = (
                                np.var(tokens_per_case)
                                if len(tokens_per_case) > 1
                                else 0
                            )

                            f.write(
                                f"    å¹³å‡å‡†ç¡®ç‡: {avg_acc:.2%} (Â±{std_acc:.2%}, æ–¹å·®:{var_acc:.6f})\n"
                            )
                            f.write(
                                f"    å¹³å‡å»¶è¿Ÿ: {avg_lat:.1f}s (Â±{std_lat:.1f}s, æ–¹å·®:{var_lat:.2f})\n"
                            )
                            f.write(
                                f"    å¹³å‡tokens/case: {int(avg_tok)} (Â±{int(std_tok)}, æ–¹å·®:{int(var_tok)})\n"
                            )
                            f.write(f"    å¹³å‡LLMè°ƒç”¨/case: {avg_llm:.1f}\n")
                    f.write("\n")
            f.write("\n")

            # 4. è¿ç»­é”™è¯¯æ¨¡å¼åˆ†æ
            if consecutive_patterns:
                f.write("4. è¿ç»­é”™è¯¯æ¨¡å¼åˆ†æ\n")
                f.write("-" * 30 + "\n")

                for run_id, patterns in consecutive_patterns.items():
                    run_label = run_labels.get(run_id, run_id)
                    if patterns:
                        f.write(f"\n{run_label} å‘ç°è¿ç»­é”™è¯¯æ¨¡å¼:\n")
                        for pattern in patterns:
                            start = min(pattern)
                            end = max(pattern)
                            length = len(pattern)
                            f.write(
                                f"             é¢˜ç›® {start}-{end} ({length}ä¸ªè¿ç»­é”™è¯¯)\n"
                            )
                f.write("\n")

            # 5. å»¶è¿Ÿæ€§èƒ½åˆ†æ
            f.write("5. å»¶è¿Ÿæ€§èƒ½åˆ†æ\n")
            f.write("-" * 30 + "\n")
            latency_df_labeled = latency_df.copy()
            latency_df_labeled["Run ID"] = latency_df_labeled["Run ID"].apply(
                lambda x: run_labels.get(x, x)
            )
            f.write(latency_df_labeled.to_string(index=False))
            f.write("\n\n")

            # 6. Tokenæ¶ˆè€—åˆ†æ
            f.write("6. Tokenæ¶ˆè€—åˆ†æ\n")
            f.write("-" * 30 + "\n")
            token_df_labeled = token_df.copy()
            token_df_labeled["Run ID"] = token_df_labeled["Run ID"].apply(
                lambda x: run_labels.get(x, x)
            )
            f.write(token_df_labeled.to_string(index=False))
            f.write("\n\n")

            # é…ç½®å› å­å½±å“åˆ†æå·²ç§»åŠ¨åˆ°1.1èŠ‚

            # 7. è°ƒç”¨é“¾å’Œå·¥å…·ä½¿ç”¨åˆ†æ
            if call_chain_summary:
                f.write("7. è°ƒç”¨é“¾å’Œå·¥å…·ä½¿ç”¨åˆ†æ\n")
                f.write("-" * 30 + "\n")
                global_summary = call_chain_summary.get("global_summary", {})
                f.write(f"æ€»ä½“ç»Ÿè®¡:\n")
                f.write(f"  - æ€»è¿è¡Œæ•°: {global_summary.get('total_runs', 0)}\n")
                f.write(f"  - æ€»æ¡ˆä¾‹æ•°: {global_summary.get('total_cases', 0)}\n")
                f.write(
                    f"  - å¹³å‡äº¤äº’è½®æ•°: {global_summary.get('avg_interaction_rounds_global', 0):.1f}\n"
                )

                # è¾“å‡ºæ¯ä¸ªrunçš„è¯¦ç»†è°ƒç”¨é“¾ç»Ÿè®¡
                run_summaries = call_chain_summary.get("run_summaries", [])
                if run_summaries:
                    f.write("\nå„Runè°ƒç”¨é“¾ç»Ÿè®¡:\n")
                    for run_summary in run_summaries:
                        run_id = run_summary.get("run_id", "")
                        run_label = run_labels.get(run_id, run_id)
                        f.write(f"\n  {run_label}:\n")
                        f.write(
                            f"    - æ€»æ¡ˆä¾‹æ•°: {run_summary.get('total_cases', 0)}\n"
                        )
                        f.write(
                            f"    - å¹³å‡äº¤äº’è½®æ•°: {run_summary.get('avg_interaction_rounds', 0):.1f}\n"
                        )
                        f.write(
                            f"    - æœ€å¤§äº¤äº’è½®æ•°: {run_summary.get('max_interaction_rounds', 0)}\n"
                        )
                        f.write(
                            f"    - æœ€å°äº¤äº’è½®æ•°: {run_summary.get('min_interaction_rounds', 0)}\n"
                        )

                        # å·¥å…·ä½¿ç”¨ç»Ÿè®¡
                        tool_stats = run_summary.get("tool_usage_stats", {})
                        if tool_stats:
                            f.write(f"    - å·¥å…·ä½¿ç”¨ç»Ÿè®¡:\n")
                            for tool_name, count in tool_stats.items():
                                f.write(f"      * {tool_name}: {count}æ¬¡\n")
                f.write("\n")

            # 8. æ—¥å¿—é”™è¯¯åˆ†æ
            if log_analyses:
                f.write("8. æ—¥å¿—é”™è¯¯åˆ†æ\n")
                f.write("-" * 30 + "\n")

                for run_id, analysis_result in log_analyses.items():
                    run_label = run_labels.get(run_id, run_id)
                    errors = analysis_result.get("errors", {})
                    warnings = analysis_result.get("warnings", {})

                    if errors or warnings:
                        f.write(f"\n{run_label} æ—¥å¿—åˆ†æ:\n")

                        if errors:
                            f.write(
                                f"  é”™è¯¯ (å…±{sum(len(v) for v in errors.values())}ä¸ª):\n"
                            )
                            for error_type, error_list in errors.items():
                                if error_list:
                                    f.write(
                                        f"    - {error_type}: {len(error_list)}ä¸ª\n"
                                    )
                                    # æ˜¾ç¤ºå‰3ä¸ªé”™è¯¯ç¤ºä¾‹
                                    for i, error in enumerate(error_list[:3]):
                                        case_id = error.get("case", "unknown")
                                        msg = error.get("message", "")[:100]
                                        f.write(f"      * Case {case_id}: {msg}...\n")

                        if warnings:
                            f.write(
                                f"  è­¦å‘Š (å…±{sum(len(v) for v in warnings.values())}ä¸ª):\n"
                            )
                            for warning_type, warning_list in warnings.items():
                                if warning_list:
                                    f.write(
                                        f"    - {warning_type}: {len(warning_list)}ä¸ª\n"
                                    )
                f.write("\n")

            # 9. æ–¹å·®åˆ†ææ±‡æ€»
            f.write("9. æ–¹å·®åˆ†ææ±‡æ€»\n")
            f.write("-" * 30 + "\n")

            # è®¡ç®—å„æŒ‡æ ‡çš„æ–¹å·®
            if len(accuracy_df) > 1:
                accuracies = [
                    float(acc.rstrip("%")) / 100 for acc in accuracy_df["Accuracy"]
                ]
                f.write(
                    f"å‡†ç¡®ç‡æ–¹å·®: {np.var(accuracies):.6f} (æ ‡å‡†å·®: {np.std(accuracies):.4f})\n"
                )

                if "Avg Latency" in latency_df.columns:
                    latencies = [
                        float(lat.replace("s", "")) for lat in latency_df["Avg Latency"]
                    ]
                    f.write(
                        f"å»¶è¿Ÿæ–¹å·®: {np.var(latencies):.2f} (æ ‡å‡†å·®: {np.std(latencies):.2f}s)\n"
                    )

                if "Total All Tokens" in token_df.columns:
                    tokens = [
                        int(tok.replace(",", ""))
                        for tok in token_df["Total All Tokens"]
                    ]
                    f.write(
                        f"Tokenæ¶ˆè€—æ–¹å·®: {np.var(tokens):.0f} (æ ‡å‡†å·®: {np.std(tokens):.0f})\n"
                    )
            else:
                f.write("æ ·æœ¬æ•°ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ–¹å·®\n")
            f.write("\n")

            # 10. LLMæ·±åº¦åˆ†æ
            f.write("10. LLMæ·±åº¦åˆ†æ\n")
            f.write("-" * 30 + "\n")
            if deep_analysis:
                f.write(deep_analysis)
            else:
                f.write("âš ï¸ æ·±åº¦åˆ†æä¸å¯ç”¨")
            f.write("\n\n")

        return report_path
