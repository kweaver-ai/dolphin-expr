#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PromptOptimizer ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ PromptOptimizer ä¼˜åŒ– Agent çš„ .dph æ–‡ä»¶ã€‚
"""
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from experiments.optimization import (
    PromptOptimizer,
    QuickPromptOptimizer,
    DeepPromptOptimizer,
    Budget
)


class MockLLMClient:
    """æ¨¡æ‹Ÿçš„ LLM å®¢æˆ·ç«¯ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®çš„ï¼‰"""

    def generate(self, prompt: str) -> str:
        """ç”Ÿæˆä¼˜åŒ–åçš„ prompt"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ LLM API
        return "ä¼˜åŒ–åçš„ prompt å†…å®¹..."


class MockSemanticJudge:
    """æ¨¡æ‹Ÿçš„ SemanticJudgeï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®çš„ï¼‰"""

    def evaluate(self, analysis_content: str, expected: str, actual: str, knowledge: str = '') -> dict:
        """è¯„ä¼°ç»“æœï¼ˆä¸ SemanticJudge æ¥å£ä¿æŒä¸€è‡´ï¼‰"""
        # ç®€å•çš„æ¨¡æ‹Ÿ
        if expected and expected.lower() in actual.lower():
            score = 1.0
        else:
            score = 0.5

        from experiments.optimization.types import SemanticJudgeDetail

        return {
            'score': score,
            'details': SemanticJudgeDetail(
                error_types=[],
                action_vector=['improve clarity'],
                candidate_injects=[],
                rationale='Mock evaluation',
                phase='exact'
            )
        }


def example_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨"""
    print("=" * 70)
    print("  ç¤ºä¾‹ 1: PromptOptimizer åŸºæœ¬ä½¿ç”¨")
    print("=" * 70)
    print()

    # 1. åˆ›å»º LLM å®¢æˆ·ç«¯å’Œ SemanticJudge
    llm_client = MockLLMClient()
    semantic_judge = MockSemanticJudge()

    # 2. åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = PromptOptimizer.create_default(
        llm_client=llm_client,
        semantic_judge=semantic_judge,
        target_section='system'  # åªä¼˜åŒ– system éƒ¨åˆ†
    )

    # 3. å‡†å¤‡ä¸Šä¸‹æ–‡
    context = {
        'agent_path': 'path/to/agent.dph',
        'failed_cases': [
            {'case_id': '001', 'error_type': 'logic_error'},
            {'case_id': '002', 'error_type': 'tool_misuse'}
        ],
        'knowledge': 'ä¸šåŠ¡è§„åˆ™ï¼š...',
        'error_types': ['logic_error', 'tool_misuse']
    }

    # 4. è®¾ç½®é¢„ç®—
    budget = Budget(max_iters=3, max_seconds=180)

    # 5. ä¼˜åŒ– Agent å†…å®¹
    target = """
system = \"\"\"
ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚
\"\"\"
"""

    print("ä¼˜åŒ–åŸå§‹å†…å®¹...")
    result = optimizer.optimize(target, context, budget)

    # 6. æŸ¥çœ‹ç»“æœ
    print(f"\nâœ“ ä¼˜åŒ–å®Œæˆï¼")
    print(f"  æœ€ä½³å¾—åˆ†: {result.best_score:.2f}")
    if result.best_candidate:
        print(f"  ä¼˜åŒ–åçš„å†…å®¹:\n{result.best_candidate.content[:200]}...")
    print()


def example_2_optimize_file():
    """ç¤ºä¾‹ 2: ä¼˜åŒ–æ–‡ä»¶ï¼ˆå¸¦å¤‡ä»½ï¼‰"""
    print("=" * 70)
    print("  ç¤ºä¾‹ 2: ä¼˜åŒ– Agent æ–‡ä»¶ï¼ˆå¸¦å¤‡ä»½ï¼‰")
    print("=" * 70)
    print()

    llm_client = MockLLMClient()
    semantic_judge = MockSemanticJudge()

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = PromptOptimizer.create_default(
        llm_client=llm_client,
        semantic_judge=semantic_judge
    )

    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ç¤ºä¾‹è·¯å¾„ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®çš„æ–‡ä»¶è·¯å¾„
    print("âš ï¸  è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç¤ºä¾‹ï¼Œä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿè·¯å¾„")
    print()

    # ç¤ºä¾‹ä»£ç ï¼ˆå®é™…ä½¿ç”¨æ—¶å–æ¶ˆæ³¨é‡Šï¼‰
    print("ä½¿ç”¨ç¤ºä¾‹ä»£ç ï¼š")
    print("""
    result = optimizer.optimize_file(
        agent_path='experiments/design/watsons_baseline/dolphins/my_agent.dph',
        context={
            'failed_cases': failed_cases,
            'knowledge': business_rules,
            'error_types': ['logic_error']
        },
        budget=Budget(max_iters=5, max_seconds=300),
        backup=True,      # è‡ªåŠ¨å¤‡ä»½åŸæ–‡ä»¶åˆ° .backup/ ç›®å½•
        replace=False     # ä¸è‡ªåŠ¨æ›¿æ¢ï¼ˆå…ˆæŸ¥çœ‹ç»“æœï¼‰
    )

    if result.best_candidate:
        print(f"âœ“ ä¼˜åŒ–æˆåŠŸï¼æœ€ä½³å¾—åˆ†: {result.best_score:.2f}")

        # æŸ¥çœ‹ä¼˜åŒ–åçš„å†…å®¹
        print("ä¼˜åŒ–åçš„å†…å®¹:")
        print(result.best_candidate.content)

        # å¦‚æœæ»¡æ„ï¼Œæ‰‹åŠ¨æ›¿æ¢
        # agent_path.write_text(result.best_candidate.content)
    """)
    print()


def example_3_quick_vs_deep():
    """ç¤ºä¾‹ 3: å¿«é€Ÿä¼˜åŒ– vs æ·±åº¦ä¼˜åŒ–"""
    print("=" * 70)
    print("  ç¤ºä¾‹ 3: å¿«é€Ÿä¼˜åŒ– vs æ·±åº¦ä¼˜åŒ–")
    print("=" * 70)
    print()

    llm_client = MockLLMClient()
    semantic_judge = MockSemanticJudge()

    # å¿«é€Ÿä¼˜åŒ–å™¨ï¼šå°‘é‡å€™é€‰ï¼Œå¿«é€Ÿæ”¶æ•›
    quick_optimizer = QuickPromptOptimizer(
        llm_client=llm_client,
        semantic_judge=semantic_judge
    )

    # æ·±åº¦ä¼˜åŒ–å™¨ï¼šæ›´å¤šå€™é€‰ï¼Œè¿½æ±‚æœ€ä½³
    deep_optimizer = DeepPromptOptimizer(
        llm_client=llm_client,
        semantic_judge=semantic_judge
    )

    target = """
system = \"\"\"
ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚
\"\"\"
"""

    context = {
        'agent_path': 'test.dph',
        'error_types': ['logic_error']
    }

    print("1. å¿«é€Ÿä¼˜åŒ–ï¼ˆ3 ä¸ªåˆå§‹å€™é€‰ï¼Œè€å¿ƒå€¼=1ï¼‰")
    quick_budget = Budget(max_iters=3)
    quick_result = quick_optimizer.optimize(target, context, quick_budget)
    print(f"   å¾—åˆ†: {quick_result.best_score:.2f}")
    print()

    print("2. æ·±åº¦ä¼˜åŒ–ï¼ˆ10 ä¸ªåˆå§‹å€™é€‰ï¼Œè€å¿ƒå€¼=5ï¼‰")
    deep_budget = Budget(max_iters=10)
    deep_result = deep_optimizer.optimize(target, context, deep_budget)
    print(f"   å¾—åˆ†: {deep_result.best_score:.2f}")
    print()

    print("å¯¹æ¯”ï¼š")
    print(f"  å¿«é€Ÿä¼˜åŒ– - è¿­ä»£: {len(quick_result.optimization_history)}, å¾—åˆ†: {quick_result.best_score:.2f}")
    print(f"  æ·±åº¦ä¼˜åŒ– - è¿­ä»£: {len(deep_result.optimization_history)}, å¾—åˆ†: {deep_result.best_score:.2f}")
    print()


def example_4_custom_configuration():
    """ç¤ºä¾‹ 4: è‡ªå®šä¹‰é…ç½®"""
    print("=" * 70)
    print("  ç¤ºä¾‹ 4: è‡ªå®šä¹‰ä¼˜åŒ–å™¨é…ç½®")
    print("=" * 70)
    print()

    llm_client = MockLLMClient()
    semantic_judge = MockSemanticJudge()

    # è‡ªå®šä¹‰é…ç½®
    optimizer = PromptOptimizer(
        llm_client=llm_client,
        semantic_judge=semantic_judge,
        target_section='system',     # åªä¼˜åŒ– system éƒ¨åˆ†
        initial_size=5,              # 5 ä¸ªåˆå§‹å€™é€‰
        use_two_phase=True,          # ä½¿ç”¨ä¸¤é˜¶æ®µè¯„ä¼°ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰
        patience=3,                  # è€å¿ƒå€¼ 3
        min_improvement=0.05         # æœ€å°æ”¹è¿› 5%
    )

    print("è‡ªå®šä¹‰é…ç½®ï¼š")
    print(f"  - ç›®æ ‡éƒ¨åˆ†: system")
    print(f"  - åˆå§‹å€™é€‰æ•°: 5")
    print(f"  - ä¸¤é˜¶æ®µè¯„ä¼°: æ˜¯ï¼ˆå…ˆå¿«é€Ÿç­›é€‰ï¼Œå†ç²¾ç¡®è¯„ä¼°ï¼‰")
    print(f"  - æ—©åœè€å¿ƒå€¼: 3")
    print(f"  - æœ€å°æ”¹è¿›: 5%")
    print()

    # ç¤ºä¾‹ï¼šä¼˜åŒ– system prompt
    target = """
system = \"\"\"
ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚
è¯·å¸®åŠ©ç”¨æˆ·åˆ†ææ•°æ®å¹¶å›ç­”é—®é¢˜ã€‚
\"\"\"
"""

    context = {
        'agent_path': 'agent.dph',
        'failed_cases': [
            {'question': 'Q1', 'expected': 'A1', 'actual': 'Wrong'},
            {'question': 'Q2', 'expected': 'A2', 'actual': 'Wrong'}
        ],
        'knowledge': 'åˆ†æè§„åˆ™ï¼š...',
        'error_types': ['logic_error', 'missing_info']
    }

    budget = Budget(max_iters=5, max_seconds=300)

    print("è¿è¡Œä¼˜åŒ–...")
    result = optimizer.optimize(target, context, budget)

    print(f"âœ“ å®Œæˆï¼æœ€ä½³å¾—åˆ†: {result.best_score:.2f}")
    print()


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘            PromptOptimizer ä½¿ç”¨ç¤ºä¾‹                              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()

    # è¿è¡Œç¤ºä¾‹
    example_1_basic_usage()
    example_2_optimize_file()
    example_3_quick_vs_deep()
    example_4_custom_configuration()

    print("=" * 70)
    print("  æ›´å¤šä¿¡æ¯")
    print("=" * 70)
    print()
    print("ğŸ“– å®Œæ•´æ–‡æ¡£:")
    print("  - experiments/optimization/README.md")
    print("  - experiments/optimization/OPTIMIZATION_METHODS.md")
    print("  - experiments/optimization/PHASE2_IMPLEMENTATION_SUMMARY.md")
    print()
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹:")
    print("  - tests/unittest/experiments/test_optimization_phase2.py")
    print()
    print("ğŸ’¡ æç¤º:")
    print("  - å¿«é€Ÿä¼˜åŒ–ï¼šä½¿ç”¨ QuickPromptOptimizer")
    print("  - æ·±åº¦ä¼˜åŒ–ï¼šä½¿ç”¨ DeepPromptOptimizer")
    print("  - æˆæœ¬ä¼˜åŒ–ï¼šå¯ç”¨ä¸¤é˜¶æ®µè¯„ä¼°ï¼ˆuse_two_phase=Trueï¼‰")
    print("  - å®‰å…¨ç¬¬ä¸€ï¼šå§‹ç»ˆå…ˆ backup=True, replace=False")
    print()


if __name__ == '__main__':
    main()
